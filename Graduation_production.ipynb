{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graduation_production.ipynb",
      "provenance": [],
      "mount_file_id": "1UXtUMtpNC-2-zaWcVxajm5D-sS6JX_D0",
      "authorship_tag": "ABX9TyPO0E6sXiCrik0T3+/RcPN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harakenken22/diveintocode-ml/blob/master/Graduation_production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxhGMZzkYKtk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/博士研究/All_Data_Kiambu_Exploratory_200422_treated_data.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "NT486bQPgLGs",
        "outputId": "fa0f3739-efc5-448c-c502-de3a06df12cf"
      },
      "source": [
        "#データの確認\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start time</th>\n",
              "      <th>Village Name</th>\n",
              "      <th>Household ID</th>\n",
              "      <th>Household ID number</th>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <th>Husband full name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Education level of husband</th>\n",
              "      <th>Major occupation of Husband</th>\n",
              "      <th>Fulltime farmer</th>\n",
              "      <th>Religious leader</th>\n",
              "      <th>Casual laborer</th>\n",
              "      <th>Civil servant</th>\n",
              "      <th>Business person</th>\n",
              "      <th>Student</th>\n",
              "      <th>Other (specify)</th>\n",
              "      <th>Religion of Husband</th>\n",
              "      <th>Mobile phone</th>\n",
              "      <th>Bicycle</th>\n",
              "      <th>Motorbike</th>\n",
              "      <th>Car/truck</th>\n",
              "      <th>Radio / stereo</th>\n",
              "      <th>TV set or DVD</th>\n",
              "      <th>Satellite dish</th>\n",
              "      <th>Refrigerator</th>\n",
              "      <th>Own stand pipe</th>\n",
              "      <th>Own borehole/well</th>\n",
              "      <th>Own water tank</th>\n",
              "      <th>Access to shared well/borehole/stand pipe</th>\n",
              "      <th>Latrine/toilet</th>\n",
              "      <th>Other:</th>\n",
              "      <th>Wood</th>\n",
              "      <th>Charcoal</th>\n",
              "      <th>Biogas (stove)</th>\n",
              "      <th>Electricity</th>\n",
              "      <th>Solar panel</th>\n",
              "      <th>Battery (large, e.g. car battery for power)</th>\n",
              "      <th>Other:__1</th>\n",
              "      <th>Gas</th>\n",
              "      <th>...</th>\n",
              "      <th>Animal Diversity</th>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <th>Height(cm)</th>\n",
              "      <th>Weight(kg)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Waist(cm)</th>\n",
              "      <th>Hip(cm)</th>\n",
              "      <th>Ratio W/H</th>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <th>Event_hypertension</th>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <th>I feel cheerful and in good spirits</th>\n",
              "      <th>I feel calm and relaxed</th>\n",
              "      <th>I feel active and vigorous</th>\n",
              "      <th>I wake up feeling fresh and rested</th>\n",
              "      <th>My daily life is filled with things that interest me</th>\n",
              "      <th>Total_happness</th>\n",
              "      <th>Activity_level_2</th>\n",
              "      <th>Steps</th>\n",
              "      <th>percentage_production</th>\n",
              "      <th>Sleeping_time</th>\n",
              "      <th>Economics_time</th>\n",
              "      <th>Crop_time</th>\n",
              "      <th>Livestock_time</th>\n",
              "      <th>BMI_EVENT</th>\n",
              "      <th>Gender_replaced</th>\n",
              "      <th>Age_std</th>\n",
              "      <th>Agrobiodiversity_std</th>\n",
              "      <th>Steps_std</th>\n",
              "      <th>MIL_std</th>\n",
              "      <th>percentage_production_std</th>\n",
              "      <th>Total_happness_std</th>\n",
              "      <th>Gender_std</th>\n",
              "      <th>BMI_std</th>\n",
              "      <th>BMI_prediction</th>\n",
              "      <th>BMI_prediction_BMI</th>\n",
              "      <th>BMI_EVENT_Prediction</th>\n",
              "      <th>BMI_prediction_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-11-04T09:49:23+0000</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>Muthumu/ Kangora</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Alex Mbugua</td>\n",
              "      <td>25</td>\n",
              "      <td>M</td>\n",
              "      <td>college/university</td>\n",
              "      <td>casual laborer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>147</td>\n",
              "      <td>57.0</td>\n",
              "      <td>26.377898</td>\n",
              "      <td>78.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.886364</td>\n",
              "      <td>23.0</td>\n",
              "      <td>120</td>\n",
              "      <td>91</td>\n",
              "      <td>Yes</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>13055.00000</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.760936</td>\n",
              "      <td>-0.815987</td>\n",
              "      <td>-0.079131</td>\n",
              "      <td>-0.184397</td>\n",
              "      <td>0.008067</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>0.057551</td>\n",
              "      <td>-0.368997</td>\n",
              "      <td>24.095865</td>\n",
              "      <td>4</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-10-28T07:39:16+0000</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Alice karaku</td>\n",
              "      <td>43</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>164</td>\n",
              "      <td>61.6</td>\n",
              "      <td>22.903034</td>\n",
              "      <td>74.0</td>\n",
              "      <td>100.5</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>32.5</td>\n",
              "      <td>121</td>\n",
              "      <td>85</td>\n",
              "      <td>No</td>\n",
              "      <td>29.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>16256.00000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.070193</td>\n",
              "      <td>-0.588249</td>\n",
              "      <td>0.306996</td>\n",
              "      <td>-1.197568</td>\n",
              "      <td>-0.564246</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>-0.591956</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>26.261291</td>\n",
              "      <td>3</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-10-28T07:18:08+0000</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Alice njoki</td>\n",
              "      <td>32</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>150</td>\n",
              "      <td>68.4</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>95.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.887850</td>\n",
              "      <td>42.4</td>\n",
              "      <td>126</td>\n",
              "      <td>69</td>\n",
              "      <td>No</td>\n",
              "      <td>24.2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.300000</td>\n",
              "      <td>15457.00000</td>\n",
              "      <td>22.700000</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.048830</td>\n",
              "      <td>-0.360510</td>\n",
              "      <td>0.210615</td>\n",
              "      <td>-0.184397</td>\n",
              "      <td>-1.074022</td>\n",
              "      <td>1.075472</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>0.809346</td>\n",
              "      <td>0.159753</td>\n",
              "      <td>26.924681</td>\n",
              "      <td>3</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-10-28T07:58:15+0000</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>Alice nyaguthie</td>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>college/university</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>155</td>\n",
              "      <td>79.5</td>\n",
              "      <td>33.090531</td>\n",
              "      <td>108.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>1.009346</td>\n",
              "      <td>42.7</td>\n",
              "      <td>140</td>\n",
              "      <td>93</td>\n",
              "      <td>Yes</td>\n",
              "      <td>48.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.600000</td>\n",
              "      <td>14941.00000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.234995</td>\n",
              "      <td>-0.360510</td>\n",
              "      <td>0.148372</td>\n",
              "      <td>-0.690983</td>\n",
              "      <td>-0.913408</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>1.312249</td>\n",
              "      <td>0.092458</td>\n",
              "      <td>26.564650</td>\n",
              "      <td>3</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-10-21T05:58:33+0000</td>\n",
              "      <td>Gababa</td>\n",
              "      <td>Gababa</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Alice Wangui</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>164</td>\n",
              "      <td>57.1</td>\n",
              "      <td>21.229923</td>\n",
              "      <td>74.5</td>\n",
              "      <td>96.5</td>\n",
              "      <td>0.772021</td>\n",
              "      <td>23.3</td>\n",
              "      <td>128</td>\n",
              "      <td>83</td>\n",
              "      <td>No</td>\n",
              "      <td>12.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>8583.50000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.680570</td>\n",
              "      <td>1.916875</td>\n",
              "      <td>-0.618516</td>\n",
              "      <td>-0.690983</td>\n",
              "      <td>0.343575</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>-0.904687</td>\n",
              "      <td>0.020861</td>\n",
              "      <td>26.181609</td>\n",
              "      <td>3</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>2019-10-07T05:41:36+0000</td>\n",
              "      <td>Gatathuthua</td>\n",
              "      <td>Gatathuthua</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Virginia waweru</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>167</td>\n",
              "      <td>81.7</td>\n",
              "      <td>29.294704</td>\n",
              "      <td>116.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.991453</td>\n",
              "      <td>38.5</td>\n",
              "      <td>117</td>\n",
              "      <td>79</td>\n",
              "      <td>No</td>\n",
              "      <td>25.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>51.333333</td>\n",
              "      <td>11640.33333</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.336724</td>\n",
              "      <td>-1.043726</td>\n",
              "      <td>-0.249779</td>\n",
              "      <td>0.828774</td>\n",
              "      <td>0.273743</td>\n",
              "      <td>-0.811321</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>0.602748</td>\n",
              "      <td>0.410629</td>\n",
              "      <td>28.266866</td>\n",
              "      <td>3</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>2019-10-28T07:58:15+0000</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>Walter kagina</td>\n",
              "      <td>44</td>\n",
              "      <td>M</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>casual laborer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>154</td>\n",
              "      <td>62.0</td>\n",
              "      <td>26.142688</td>\n",
              "      <td>92.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.910891</td>\n",
              "      <td>24.0</td>\n",
              "      <td>121</td>\n",
              "      <td>79</td>\n",
              "      <td>No</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>20066.00000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.171923</td>\n",
              "      <td>-0.360510</td>\n",
              "      <td>0.766586</td>\n",
              "      <td>-0.690983</td>\n",
              "      <td>1.530726</td>\n",
              "      <td>1.075472</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>0.013587</td>\n",
              "      <td>-0.274927</td>\n",
              "      <td>24.599143</td>\n",
              "      <td>4</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2019-10-07T06:17:02+0000</td>\n",
              "      <td>Muthumu migudaini</td>\n",
              "      <td>Kangora</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Walter kariuki</td>\n",
              "      <td>59</td>\n",
              "      <td>M</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>fulltime farmer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>166</td>\n",
              "      <td>58.8</td>\n",
              "      <td>21.338366</td>\n",
              "      <td>85.5</td>\n",
              "      <td>94.5</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>22.9</td>\n",
              "      <td>139</td>\n",
              "      <td>97</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>81.909867</td>\n",
              "      <td>13765.47333</td>\n",
              "      <td>24.285714</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.697864</td>\n",
              "      <td>1.689137</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>-1.197568</td>\n",
              "      <td>-0.963288</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>-0.884418</td>\n",
              "      <td>-0.514365</td>\n",
              "      <td>23.318147</td>\n",
              "      <td>2</td>\n",
              "      <td>TURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>2019-11-11T06:39:32+0000</td>\n",
              "      <td>Wangige</td>\n",
              "      <td>Wangige</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>William Gathungu</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>primary school</td>\n",
              "      <td>fulltime farmer business person</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>185</td>\n",
              "      <td>70.9</td>\n",
              "      <td>20.715851</td>\n",
              "      <td>85.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>13.7</td>\n",
              "      <td>139</td>\n",
              "      <td>87</td>\n",
              "      <td>No</td>\n",
              "      <td>48.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>81.909867</td>\n",
              "      <td>13765.47333</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.070193</td>\n",
              "      <td>0.322706</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>-0.690983</td>\n",
              "      <td>0.008067</td>\n",
              "      <td>0.446541</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>-1.000776</td>\n",
              "      <td>-0.416274</td>\n",
              "      <td>23.842931</td>\n",
              "      <td>2</td>\n",
              "      <td>TURE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>2019-09-23T06:21:35+0000</td>\n",
              "      <td>Kiiniki</td>\n",
              "      <td>Kiiniki</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>Zipporah Nduta</td>\n",
              "      <td>42</td>\n",
              "      <td>F</td>\n",
              "      <td>primary school</td>\n",
              "      <td>fulltime farmer casual laborer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Christianity</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>161</td>\n",
              "      <td>70.9</td>\n",
              "      <td>27.352340</td>\n",
              "      <td>96.5</td>\n",
              "      <td>112.5</td>\n",
              "      <td>0.857778</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119</td>\n",
              "      <td>93</td>\n",
              "      <td>Yes</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>36610.00000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.031536</td>\n",
              "      <td>-0.815987</td>\n",
              "      <td>2.762244</td>\n",
              "      <td>-0.184397</td>\n",
              "      <td>-1.087989</td>\n",
              "      <td>-2.069182</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>0.239690</td>\n",
              "      <td>0.469426</td>\n",
              "      <td>28.581431</td>\n",
              "      <td>3</td>\n",
              "      <td>TURE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 219 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   start time  ... BMI_prediction_result\n",
              "0    2019-11-04T09:49:23+0000  ...                 FALSE\n",
              "1    2019-10-28T07:39:16+0000  ...                 FALSE\n",
              "2    2019-10-28T07:18:08+0000  ...                 FALSE\n",
              "3    2019-10-28T07:58:15+0000  ...                 FALSE\n",
              "4    2019-10-21T05:58:33+0000  ...                 FALSE\n",
              "..                        ...  ...                   ...\n",
              "127  2019-10-07T05:41:36+0000  ...                 FALSE\n",
              "128  2019-10-28T07:58:15+0000  ...                 FALSE\n",
              "129  2019-10-07T06:17:02+0000  ...                  TURE\n",
              "130  2019-11-11T06:39:32+0000  ...                  TURE\n",
              "131  2019-09-23T06:21:35+0000  ...                  TURE\n",
              "\n",
              "[132 rows x 219 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "TOekGR8WZdVj",
        "outputId": "39c92786-5f4a-4a29-f918-4a8b42156f43"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Household ID number</th>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fulltime farmer</th>\n",
              "      <th>Religious leader</th>\n",
              "      <th>Casual laborer</th>\n",
              "      <th>Civil servant</th>\n",
              "      <th>Business person</th>\n",
              "      <th>Student</th>\n",
              "      <th>Other (specify)</th>\n",
              "      <th>Mobile phone</th>\n",
              "      <th>Bicycle</th>\n",
              "      <th>Motorbike</th>\n",
              "      <th>Car/truck</th>\n",
              "      <th>Radio / stereo</th>\n",
              "      <th>TV set or DVD</th>\n",
              "      <th>Satellite dish</th>\n",
              "      <th>Refrigerator</th>\n",
              "      <th>Own stand pipe</th>\n",
              "      <th>Own borehole/well</th>\n",
              "      <th>Own water tank</th>\n",
              "      <th>Access to shared well/borehole/stand pipe</th>\n",
              "      <th>Latrine/toilet</th>\n",
              "      <th>Other:</th>\n",
              "      <th>Wood</th>\n",
              "      <th>Charcoal</th>\n",
              "      <th>Biogas (stove)</th>\n",
              "      <th>Electricity</th>\n",
              "      <th>Solar panel</th>\n",
              "      <th>Battery (large, e.g. car battery for power)</th>\n",
              "      <th>Other:__1</th>\n",
              "      <th>Gas</th>\n",
              "      <th>MIL</th>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <th>walking min from your house to your favorite market</th>\n",
              "      <th>African nightshade_V</th>\n",
              "      <th>Amaranth_V</th>\n",
              "      <th>Apple local_F</th>\n",
              "      <th>Avocado_F</th>\n",
              "      <th>...</th>\n",
              "      <th>Goat</th>\n",
              "      <th>Sheep</th>\n",
              "      <th>Animal Diversity</th>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <th>Height(cm)</th>\n",
              "      <th>Weight(kg)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Waist(cm)</th>\n",
              "      <th>Hip(cm)</th>\n",
              "      <th>Ratio W/H</th>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <th>I feel cheerful and in good spirits</th>\n",
              "      <th>I feel calm and relaxed</th>\n",
              "      <th>I feel active and vigorous</th>\n",
              "      <th>I wake up feeling fresh and rested</th>\n",
              "      <th>My daily life is filled with things that interest me</th>\n",
              "      <th>Total_happness</th>\n",
              "      <th>Activity_level_2</th>\n",
              "      <th>Steps</th>\n",
              "      <th>percentage_production</th>\n",
              "      <th>Sleeping_time</th>\n",
              "      <th>Economics_time</th>\n",
              "      <th>Crop_time</th>\n",
              "      <th>Livestock_time</th>\n",
              "      <th>BMI_EVENT</th>\n",
              "      <th>Gender_replaced</th>\n",
              "      <th>Age_std</th>\n",
              "      <th>Agrobiodiversity_std</th>\n",
              "      <th>Steps_std</th>\n",
              "      <th>MIL_std</th>\n",
              "      <th>percentage_production_std</th>\n",
              "      <th>Total_happness_std</th>\n",
              "      <th>Gender_std</th>\n",
              "      <th>BMI_std</th>\n",
              "      <th>BMI_prediction</th>\n",
              "      <th>BMI_prediction_BMI</th>\n",
              "      <th>BMI_EVENT_Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.0</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>132.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.242424</td>\n",
              "      <td>4.553030</td>\n",
              "      <td>42.318182</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>0.106061</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053030</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.098485</td>\n",
              "      <td>0.128788</td>\n",
              "      <td>0.174242</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.310606</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.530303</td>\n",
              "      <td>0.219697</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.568182</td>\n",
              "      <td>0.492424</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.786325</td>\n",
              "      <td>3.372093</td>\n",
              "      <td>1.371212</td>\n",
              "      <td>24.772727</td>\n",
              "      <td>7.053030</td>\n",
              "      <td>0.621212</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.106061</td>\n",
              "      <td>1.469697</td>\n",
              "      <td>8.583333</td>\n",
              "      <td>166.454545</td>\n",
              "      <td>71.862879</td>\n",
              "      <td>26.066021</td>\n",
              "      <td>92.762121</td>\n",
              "      <td>104.698864</td>\n",
              "      <td>0.885072</td>\n",
              "      <td>27.179545</td>\n",
              "      <td>129.734848</td>\n",
              "      <td>83.636364</td>\n",
              "      <td>33.940682</td>\n",
              "      <td>3.515625</td>\n",
              "      <td>3.515625</td>\n",
              "      <td>4.312500</td>\n",
              "      <td>3.820312</td>\n",
              "      <td>4.437500</td>\n",
              "      <td>19.601562</td>\n",
              "      <td>81.909867</td>\n",
              "      <td>13765.473333</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>2.954545</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.008067</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>26.066021</td>\n",
              "      <td>3.053030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.426705</td>\n",
              "      <td>1.394178</td>\n",
              "      <td>9.788074</td>\n",
              "      <td>0.387164</td>\n",
              "      <td>0.087039</td>\n",
              "      <td>0.309088</td>\n",
              "      <td>0.122621</td>\n",
              "      <td>0.318578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.224948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.299104</td>\n",
              "      <td>0.336241</td>\n",
              "      <td>0.380763</td>\n",
              "      <td>0.288575</td>\n",
              "      <td>0.239515</td>\n",
              "      <td>0.318578</td>\n",
              "      <td>0.464505</td>\n",
              "      <td>0.499826</td>\n",
              "      <td>0.374098</td>\n",
              "      <td>0.500982</td>\n",
              "      <td>0.415619</td>\n",
              "      <td>0.374098</td>\n",
              "      <td>0.209092</td>\n",
              "      <td>0.497216</td>\n",
              "      <td>0.501847</td>\n",
              "      <td>0.172073</td>\n",
              "      <td>0.122621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.318578</td>\n",
              "      <td>0.411663</td>\n",
              "      <td>1.973371</td>\n",
              "      <td>0.597773</td>\n",
              "      <td>10.590642</td>\n",
              "      <td>4.671359</td>\n",
              "      <td>0.486933</td>\n",
              "      <td>0.473200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.327617</td>\n",
              "      <td>...</td>\n",
              "      <td>0.288575</td>\n",
              "      <td>0.309088</td>\n",
              "      <td>1.115056</td>\n",
              "      <td>4.391250</td>\n",
              "      <td>8.728617</td>\n",
              "      <td>13.822376</td>\n",
              "      <td>5.350698</td>\n",
              "      <td>15.649718</td>\n",
              "      <td>11.470704</td>\n",
              "      <td>0.110017</td>\n",
              "      <td>9.701772</td>\n",
              "      <td>17.385112</td>\n",
              "      <td>11.928715</td>\n",
              "      <td>10.129467</td>\n",
              "      <td>1.152391</td>\n",
              "      <td>1.172095</td>\n",
              "      <td>0.835747</td>\n",
              "      <td>1.101239</td>\n",
              "      <td>0.820505</td>\n",
              "      <td>3.175142</td>\n",
              "      <td>79.425724</td>\n",
              "      <td>8286.708576</td>\n",
              "      <td>14.314382</td>\n",
              "      <td>87.096184</td>\n",
              "      <td>160.452454</td>\n",
              "      <td>167.433154</td>\n",
              "      <td>74.035705</td>\n",
              "      <td>0.931744</td>\n",
              "      <td>0.501386</td>\n",
              "      <td>0.995735</td>\n",
              "      <td>1.000057</td>\n",
              "      <td>0.999603</td>\n",
              "      <td>0.999682</td>\n",
              "      <td>0.999608</td>\n",
              "      <td>0.998472</td>\n",
              "      <td>0.999972</td>\n",
              "      <td>1.000131</td>\n",
              "      <td>0.337772</td>\n",
              "      <td>1.807082</td>\n",
              "      <td>0.583676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>15.615705</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>0.606481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.269583</td>\n",
              "      <td>-1.726941</td>\n",
              "      <td>-1.653920</td>\n",
              "      <td>-1.197568</td>\n",
              "      <td>-2.659218</td>\n",
              "      <td>-3.327044</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>-1.954074</td>\n",
              "      <td>-0.624212</td>\n",
              "      <td>22.730463</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>61.225000</td>\n",
              "      <td>22.067665</td>\n",
              "      <td>80.500000</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>0.828460</td>\n",
              "      <td>22.975000</td>\n",
              "      <td>118.750000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>21.833333</td>\n",
              "      <td>8314.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>322.500000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.743642</td>\n",
              "      <td>-0.588249</td>\n",
              "      <td>-0.651025</td>\n",
              "      <td>-0.690983</td>\n",
              "      <td>-0.634078</td>\n",
              "      <td>-0.496855</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>-0.748100</td>\n",
              "      <td>-0.233329</td>\n",
              "      <td>24.821688</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>70.050000</td>\n",
              "      <td>25.423333</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>104.250000</td>\n",
              "      <td>0.876477</td>\n",
              "      <td>27.650000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.515625</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>68.833333</td>\n",
              "      <td>13021.333335</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>39.631579</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070193</td>\n",
              "      <td>-0.360510</td>\n",
              "      <td>-0.083193</td>\n",
              "      <td>-0.184397</td>\n",
              "      <td>0.008067</td>\n",
              "      <td>-0.182390</td>\n",
              "      <td>-0.951935</td>\n",
              "      <td>-0.120872</td>\n",
              "      <td>0.009580</td>\n",
              "      <td>26.121252</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>173.250000</td>\n",
              "      <td>81.400000</td>\n",
              "      <td>29.281309</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>110.500000</td>\n",
              "      <td>0.939539</td>\n",
              "      <td>33.025000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>40.575000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>102.500000</td>\n",
              "      <td>17223.500000</td>\n",
              "      <td>47.850000</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>337.500000</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.782299</td>\n",
              "      <td>0.550444</td>\n",
              "      <td>0.423703</td>\n",
              "      <td>0.322188</td>\n",
              "      <td>0.682263</td>\n",
              "      <td>0.761006</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>0.600245</td>\n",
              "      <td>0.193302</td>\n",
              "      <td>27.104166</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>111.800000</td>\n",
              "      <td>43.671875</td>\n",
              "      <td>169.500000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>1.738462</td>\n",
              "      <td>46.900000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>352.333333</td>\n",
              "      <td>44728.666670</td>\n",
              "      <td>76.500000</td>\n",
              "      <td>870.000000</td>\n",
              "      <td>810.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.799593</td>\n",
              "      <td>2.827830</td>\n",
              "      <td>3.741576</td>\n",
              "      <td>4.881459</td>\n",
              "      <td>2.682961</td>\n",
              "      <td>1.704403</td>\n",
              "      <td>1.042481</td>\n",
              "      <td>3.290070</td>\n",
              "      <td>1.179044</td>\n",
              "      <td>32.377887</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 205 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Household ID number  ...  BMI_EVENT_Prediction\n",
              "count           132.000000  ...            132.000000\n",
              "mean              4.242424  ...              3.053030\n",
              "std               3.426705  ...              0.583676\n",
              "min               1.000000  ...              2.000000\n",
              "25%               2.000000  ...              3.000000\n",
              "50%               3.000000  ...              3.000000\n",
              "75%               5.000000  ...              3.000000\n",
              "max              16.000000  ...              4.000000\n",
              "\n",
              "[8 rows x 205 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qAmYK9Tb3Jf",
        "outputId": "8ed806b3-2ce0-4d59-b734-9c447537b003"
      },
      "source": [
        "#forでdescribeを行う場合\n",
        "for i in range(len(df.columns)):\n",
        "  print(df.iloc[:,i].describe())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count                          132\n",
            "unique                          72\n",
            "top       2019-09-23T11:09:53+0000\n",
            "freq                             2\n",
            "Name: start time, dtype: object\n",
            "count         132\n",
            "unique         23\n",
            "top       Muthumu\n",
            "freq           16\n",
            "Name: Village Name, dtype: object\n",
            "count                      132\n",
            "unique                      15\n",
            "top       Ruku shopping center\n",
            "freq                        14\n",
            "Name: Household ID, dtype: object\n",
            "count    132.000000\n",
            "mean       4.242424\n",
            "std        3.426705\n",
            "min        1.000000\n",
            "25%        2.000000\n",
            "50%        3.000000\n",
            "75%        5.000000\n",
            "max       16.000000\n",
            "Name: Household ID number, dtype: float64\n",
            "count    132.000000\n",
            "mean       4.553030\n",
            "std        1.394178\n",
            "min        2.000000\n",
            "25%        4.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max       10.000000\n",
            "Name: Number of people sharing the same pot, dtype: float64\n",
            "count              132\n",
            "unique             131\n",
            "top       David Mungai\n",
            "freq                 2\n",
            "Name: Husband full name, dtype: object\n",
            "count    132.000000\n",
            "mean      42.318182\n",
            "std        9.788074\n",
            "min       20.000000\n",
            "25%       35.000000\n",
            "50%       43.000000\n",
            "75%       50.000000\n",
            "max       60.000000\n",
            "Name: Age, dtype: float64\n",
            "count     132\n",
            "unique      2\n",
            "top         F\n",
            "freq       69\n",
            "Name: Gender, dtype: object\n",
            "count                  132\n",
            "unique                   5\n",
            "top       secondary school\n",
            "freq                    60\n",
            "Name: Education level of husband, dtype: object\n",
            "count                 132\n",
            "unique                 13\n",
            "top       fulltime farmer\n",
            "freq                   95\n",
            "Name: Major occupation of Husband, dtype: object\n",
            "count    132.000000\n",
            "mean       0.818182\n",
            "std        0.387164\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Fulltime farmer, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.007576\n",
            "std        0.087039\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Religious leader, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.106061\n",
            "std        0.309088\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Casual laborer, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Civil servant, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.113636\n",
            "std        0.318578\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Business person, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Student, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.053030\n",
            "std        0.224948\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Other (specify), dtype: float64\n",
            "count              132\n",
            "unique               1\n",
            "top       Christianity\n",
            "freq               132\n",
            "Name: Religion of Husband, dtype: object\n",
            "count    132.0\n",
            "mean       1.0\n",
            "std        0.0\n",
            "min        1.0\n",
            "25%        1.0\n",
            "50%        1.0\n",
            "75%        1.0\n",
            "max        1.0\n",
            "Name: Mobile phone, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.098485\n",
            "std        0.299104\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Bicycle, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.128788\n",
            "std        0.336241\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Motorbike, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.174242\n",
            "std        0.380763\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Car/truck, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.909091\n",
            "std        0.288575\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Radio / stereo, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.939394\n",
            "std        0.239515\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: TV set or DVD, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.113636\n",
            "std        0.318578\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Satellite dish, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.310606\n",
            "std        0.464505\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Refrigerator, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.454545\n",
            "std        0.499826\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Own stand pipe, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.833333\n",
            "std        0.374098\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Own borehole/well, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.530303\n",
            "std        0.500982\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Own water tank, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.219697\n",
            "std        0.415619\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Access to shared well/borehole/stand pipe, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.833333\n",
            "std        0.374098\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Latrine/toilet, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.045455\n",
            "std        0.209092\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Other:, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.568182\n",
            "std        0.497216\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Wood, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.492424\n",
            "std        0.501847\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Charcoal, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Biogas (stove), dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Electricity, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Solar panel, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Battery (large, e.g. car battery for power), dtype: float64\n",
            "count    132.000000\n",
            "mean       0.113636\n",
            "std        0.318578\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Other:__1, dtype: float64\n",
            "count    117.000000\n",
            "mean       0.786325\n",
            "std        0.411663\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Gas, dtype: float64\n",
            "count              130\n",
            "unique               9\n",
            "top       5000 - 10000\n",
            "freq                36\n",
            "Name: Monthly income(Ksh), dtype: object\n",
            "count    132.000000\n",
            "mean       3.372093\n",
            "std        1.973371\n",
            "min        1.000000\n",
            "25%        2.000000\n",
            "50%        3.000000\n",
            "75%        4.000000\n",
            "max       13.000000\n",
            "Name: MIL, dtype: float64\n",
            "count     132\n",
            "unique      2\n",
            "top         F\n",
            "freq       69\n",
            "Name: Gender__1, dtype: object\n",
            "count    132.000000\n",
            "mean       1.371212\n",
            "std        0.597773\n",
            "min        1.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        2.000000\n",
            "max        3.000000\n",
            "Name: Number of cultivation field, dtype: float64\n",
            "count    132.000000\n",
            "mean      24.772727\n",
            "std       10.590642\n",
            "min        5.000000\n",
            "25%       15.000000\n",
            "50%       30.000000\n",
            "75%       30.000000\n",
            "max       50.000000\n",
            "Name: walking min from your house to Wangige market?, dtype: float64\n",
            "count    132.000000\n",
            "mean       7.053030\n",
            "std        4.671359\n",
            "min        2.000000\n",
            "25%        5.000000\n",
            "50%        5.000000\n",
            "75%       10.000000\n",
            "max       25.000000\n",
            "Name: walking min from your house to your favorite market, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.621212\n",
            "std        0.486933\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: African nightshade_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.666667\n",
            "std        0.473200\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Amaranth_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Apple local_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.121212\n",
            "std        0.327617\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Avocado_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.242424\n",
            "std        0.430182\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Banana_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.303030\n",
            "std        0.461319\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Beans_P, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Beetroot_R, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.045455\n",
            "std        0.209092\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Broccoli_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.181818\n",
            "std        0.387164\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cabbage_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Carrot_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cassava_R, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.143939\n",
            "std        0.352366\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Chili pepper_S, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Coco-yam_R, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.250000\n",
            "std        0.434662\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.250000\n",
            "max        1.000000\n",
            "Name: Coriander_S, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cowpeas_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.128788\n",
            "std        0.336241\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cucumber_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Custard apple_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Edible gourd_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.075758\n",
            "std        0.265618\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Eggplant_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Finger millet_C, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: French beans_P, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Garden peas_P, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Garlic_S, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Ginger_S, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Green grams_P, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Green pepper_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Guava_F, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Karela_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Kinaa_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Lemon_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.166667\n",
            "std        0.374098\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Lettuce_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.553030\n",
            "std        0.499074\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Maize_C, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Mango_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Muu_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Okra_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.090909\n",
            "std        0.288575\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Onion_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Orange_F, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Passion fruit_F, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pawpaw_F, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pearl millet_C, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pigeon peas_P, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pineapple_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.272727\n",
            "std        0.447058\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Potato_R, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.075758\n",
            "std        0.265618\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Pumpkin_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Sorghum_C, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.780303\n",
            "std        0.415619\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Spinach_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.068182\n",
            "std        0.253018\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Sugarcane_SC, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.803030\n",
            "std        0.399224\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Sukuma(Kale)_V, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Sweet potato_R, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Tamarind_F, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Tangerine_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.136364\n",
            "std        0.344482\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Tomato_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Watermelon_V, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: White sapote_F, dtype: float64\n",
            "count    132.000000\n",
            "mean       5.924242\n",
            "std        3.541728\n",
            "min        0.000000\n",
            "25%        4.000000\n",
            "50%        5.000000\n",
            "75%        7.000000\n",
            "max       17.000000\n",
            "Name: Cultivation diversity, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.568182\n",
            "std        0.527028\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: Cultivation diversity_Cereals, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.333333\n",
            "std        0.533842\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: Cultivation diversity_Root, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.083333\n",
            "std        0.277438\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cultivation diversity_Suger, dtype: float64\n",
            "count    132.000000\n",
            "mean       3.848485\n",
            "std        2.177206\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "max       11.000000\n",
            "Name: Cultivation diversity_Vegetable, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.318182\n",
            "std        0.499132\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: Cultivation diversity_Palse, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.393939\n",
            "std        0.650984\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: Cultivation diversity_Fruits, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.393939\n",
            "std        0.602255\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        2.000000\n",
            "Name: Cultivation diversity_Spice, dtype: float64\n",
            "count          89\n",
            "unique         21\n",
            "top       Avocado\n",
            "freq           26\n",
            "Name: Wild plant resources, dtype: object\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: African nightshade_V__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.098485\n",
            "std        0.299104\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Amaranth_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Apple local_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.477273\n",
            "std        0.501386\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Avocado_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.196970\n",
            "std        0.399224\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Banana_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Beans_P__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Beetroot_R__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Broccoli_V__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Cabbage_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Carrot_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Cassava_R__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Chili pepper_S__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Coco-yam_R__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Coriander_S__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Cowpeas_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Cucumber_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Custard apple_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Edible gourd_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Eggplant_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Finger millet_C__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: French beans_P__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Garden peas_P__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Garlic_S__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Ginger_S__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Green grams_P__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Green pepper_V__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.075758\n",
            "std        0.265618\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Guava_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Karela_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Kinaa_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Lemon_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Lettuce_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Maize_C__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.098485\n",
            "std        0.299104\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Mango_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Muu_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Okra_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Onion_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Orange_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Passion fruit_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Pawpaw_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pearl millet_C__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pigeon peas_P__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pineapple_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Potato_R__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Pumpkin_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Sorghum_C__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Spinach_V__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.075758\n",
            "std        0.265618\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Sugarcane_SC__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Sukuma(Kale)_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Sweet potato_R__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Tamarind_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Tangerine_F__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Tomato_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Watermelon_V__1, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: White sapote_F__1, dtype: float64\n",
            "count    132.000000\n",
            "mean       1.189394\n",
            "std        1.242582\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        2.000000\n",
            "max        6.000000\n",
            "Name: Wild Diversity, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Wild Diversity_Cereals, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Wild Diversity_Root, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.075758\n",
            "std        0.265618\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Wild Diversity_Suger, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.159091\n",
            "std        0.663435\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        5.000000\n",
            "Name: Wild Diversity_Vegetable, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Wild Diversity_Palse, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.924242\n",
            "std        0.993269\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        4.000000\n",
            "Name: Wild Diversity_Fruits, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.030303\n",
            "std        0.172073\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Wild Diversity_Spice, dtype: float64\n",
            "count     108\n",
            "unique     21\n",
            "top       Caw\n",
            "freq       32\n",
            "Name: Animal Resources, dtype: object\n",
            "count    132.000000\n",
            "mean       0.598485\n",
            "std        0.492072\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        1.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Caw, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.280303\n",
            "std        0.450858\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Pig, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.378788\n",
            "std        0.486933\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Chiken, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.015152\n",
            "std        0.122621\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Rabbit, dtype: float64\n",
            "count    132.0\n",
            "mean       0.0\n",
            "std        0.0\n",
            "min        0.0\n",
            "25%        0.0\n",
            "50%        0.0\n",
            "75%        0.0\n",
            "max        0.0\n",
            "Name: Snake, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.090909\n",
            "std        0.288575\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Goat, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.106061\n",
            "std        0.309088\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        0.000000\n",
            "max        1.000000\n",
            "Name: Sheep, dtype: float64\n",
            "count    132.000000\n",
            "mean       1.469697\n",
            "std        1.115056\n",
            "min        0.000000\n",
            "25%        1.000000\n",
            "50%        1.000000\n",
            "75%        2.000000\n",
            "max        5.000000\n",
            "Name: Animal Diversity, dtype: float64\n",
            "count    132.000000\n",
            "mean       8.583333\n",
            "std        4.391250\n",
            "min        1.000000\n",
            "25%        6.000000\n",
            "50%        7.000000\n",
            "75%       11.000000\n",
            "max       21.000000\n",
            "Name: Agrobiodiversity, dtype: float64\n",
            "count    132.000000\n",
            "mean     166.454545\n",
            "std        8.728617\n",
            "min      145.000000\n",
            "25%      160.000000\n",
            "50%      166.000000\n",
            "75%      173.250000\n",
            "max      187.000000\n",
            "Name: Height(cm), dtype: float64\n",
            "count    132.000000\n",
            "mean      71.862879\n",
            "std       13.822376\n",
            "min       42.000000\n",
            "25%       61.225000\n",
            "50%       70.050000\n",
            "75%       81.400000\n",
            "max      111.800000\n",
            "Name: Weight(kg), dtype: float64\n",
            "count    132.000000\n",
            "mean      26.066021\n",
            "std        5.350698\n",
            "min       15.615705\n",
            "25%       22.067665\n",
            "50%       25.423333\n",
            "75%       29.281309\n",
            "max       43.671875\n",
            "Name: BMI, dtype: float64\n",
            "count    132.000000\n",
            "mean      92.762121\n",
            "std       15.649718\n",
            "min       65.000000\n",
            "25%       80.500000\n",
            "50%       92.500000\n",
            "75%      103.000000\n",
            "max      169.500000\n",
            "Name: Waist(cm), dtype: float64\n",
            "count    132.000000\n",
            "mean     104.698864\n",
            "std       11.470704\n",
            "min       78.000000\n",
            "25%       96.500000\n",
            "50%      104.250000\n",
            "75%      110.500000\n",
            "max      136.000000\n",
            "Name: Hip(cm), dtype: float64\n",
            "count    132.000000\n",
            "mean       0.885072\n",
            "std        0.110017\n",
            "min        0.606481\n",
            "25%        0.828460\n",
            "50%        0.876477\n",
            "75%        0.939539\n",
            "max        1.738462\n",
            "Name: Ratio W/H, dtype: float64\n",
            "count    132.000000\n",
            "mean      27.179545\n",
            "std        9.701772\n",
            "min        0.000000\n",
            "25%       22.975000\n",
            "50%       27.650000\n",
            "75%       33.025000\n",
            "max       46.900000\n",
            "Name: Body Fat (%), dtype: float64\n",
            "count    132.000000\n",
            "mean     129.734848\n",
            "std       17.385112\n",
            "min       96.000000\n",
            "25%      118.750000\n",
            "50%      127.000000\n",
            "75%      139.000000\n",
            "max      200.000000\n",
            "Name: Systolic blood pressure(mmHg), dtype: float64\n",
            "count    132.000000\n",
            "mean      83.636364\n",
            "std       11.928715\n",
            "min       62.000000\n",
            "25%       76.000000\n",
            "50%       81.500000\n",
            "75%       91.000000\n",
            "max      137.000000\n",
            "Name: Diastolic blood pressure(mmHg), dtype: float64\n",
            "count     132\n",
            "unique      2\n",
            "top        No\n",
            "freq       86\n",
            "Name: Event_hypertension, dtype: object\n",
            "count    132.000000\n",
            "mean      33.940682\n",
            "std       10.129467\n",
            "min       12.600000\n",
            "25%       27.000000\n",
            "50%       33.000000\n",
            "75%       40.575000\n",
            "max       76.000000\n",
            "Name: Grasping power(kg), dtype: float64\n",
            "count    132.000000\n",
            "mean       3.515625\n",
            "std        1.152391\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        3.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: I feel cheerful and in good spirits, dtype: float64\n",
            "count    132.000000\n",
            "mean       3.515625\n",
            "std        1.172095\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        3.515625\n",
            "75%        4.000000\n",
            "max        5.000000\n",
            "Name: I feel calm and relaxed, dtype: float64\n",
            "count    132.000000\n",
            "mean       4.312500\n",
            "std        0.835747\n",
            "min        1.000000\n",
            "25%        4.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: I feel active and vigorous, dtype: float64\n",
            "count    132.000000\n",
            "mean       3.820312\n",
            "std        1.101239\n",
            "min        0.000000\n",
            "25%        3.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: I wake up feeling fresh and rested, dtype: float64\n",
            "count    128.000000\n",
            "mean       4.437500\n",
            "std        0.820505\n",
            "min        2.000000\n",
            "25%        4.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: My daily life is filled with things that interest me, dtype: float64\n",
            "count    132.000000\n",
            "mean      19.601562\n",
            "std        3.175142\n",
            "min        9.000000\n",
            "25%       18.000000\n",
            "50%       19.000000\n",
            "75%       22.000000\n",
            "max       25.000000\n",
            "Name: Total_happness, dtype: float64\n",
            "count    132.000000\n",
            "mean      81.909867\n",
            "std       79.425724\n",
            "min        0.000000\n",
            "25%       21.833333\n",
            "50%       68.833333\n",
            "75%      102.500000\n",
            "max      352.333333\n",
            "Name: Activity_level_2, dtype: float64\n",
            "count      132.000000\n",
            "mean     13765.473333\n",
            "std       8286.708576\n",
            "min          0.000000\n",
            "25%       8314.000000\n",
            "50%      13021.333335\n",
            "75%      17223.500000\n",
            "max      44728.666670\n",
            "Name: Steps, dtype: float64\n",
            "count    132.000000\n",
            "mean      38.195515\n",
            "std       14.314382\n",
            "min        0.000000\n",
            "25%       29.000000\n",
            "50%       38.195515\n",
            "75%       47.850000\n",
            "max       76.500000\n",
            "Name: percentage_production, dtype: float64\n",
            "count    132.000000\n",
            "mean     530.842105\n",
            "std       87.096184\n",
            "min      270.000000\n",
            "25%      480.000000\n",
            "50%      530.842105\n",
            "75%      570.000000\n",
            "max      870.000000\n",
            "Name: Sleeping_time, dtype: float64\n",
            "count    132.000000\n",
            "mean     392.526316\n",
            "std      160.452454\n",
            "min        0.000000\n",
            "25%      322.500000\n",
            "50%      392.526316\n",
            "75%      480.000000\n",
            "max      810.000000\n",
            "Name: Economics_time, dtype: float64\n",
            "count    132.000000\n",
            "mean     272.210526\n",
            "std      167.433154\n",
            "min        0.000000\n",
            "25%      180.000000\n",
            "50%      272.210526\n",
            "75%      337.500000\n",
            "max      720.000000\n",
            "Name: Crop_time, dtype: float64\n",
            "count    132.000000\n",
            "mean      49.263158\n",
            "std       74.035705\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%       39.631579\n",
            "75%       49.263158\n",
            "max      390.000000\n",
            "Name: Livestock_time, dtype: float64\n",
            "count    132.000000\n",
            "mean       2.954545\n",
            "std        0.931744\n",
            "min        1.000000\n",
            "25%        2.000000\n",
            "50%        3.000000\n",
            "75%        4.000000\n",
            "max        4.000000\n",
            "Name: BMI_EVENT, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.477273\n",
            "std        0.501386\n",
            "min        0.000000\n",
            "25%        0.000000\n",
            "50%        0.000000\n",
            "75%        1.000000\n",
            "max        1.000000\n",
            "Name: Gender_replaced, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.000832\n",
            "std        0.995735\n",
            "min       -2.269583\n",
            "25%       -0.743642\n",
            "50%        0.070193\n",
            "75%        0.782299\n",
            "max        1.799593\n",
            "Name: Age_std, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.000076\n",
            "std        1.000057\n",
            "min       -1.726941\n",
            "25%       -0.588249\n",
            "50%       -0.360510\n",
            "75%        0.550444\n",
            "max        2.827830\n",
            "Name: Agrobiodiversity_std, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.006571\n",
            "std        0.999603\n",
            "min       -1.653920\n",
            "25%       -0.651025\n",
            "50%       -0.083193\n",
            "75%        0.423703\n",
            "max        3.741576\n",
            "Name: Steps_std, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.004100\n",
            "std        0.999682\n",
            "min       -1.197568\n",
            "25%       -0.690983\n",
            "50%       -0.184397\n",
            "75%        0.322188\n",
            "max        4.881459\n",
            "Name: MIL_std, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.008067\n",
            "std        0.999608\n",
            "min       -2.659218\n",
            "25%       -0.634078\n",
            "50%        0.008067\n",
            "75%        0.682263\n",
            "max        2.682961\n",
            "Name: percentage_production_std, dtype: float64\n",
            "count    132.000000\n",
            "mean       0.006781\n",
            "std        0.998472\n",
            "min       -3.327044\n",
            "25%       -0.496855\n",
            "50%       -0.182390\n",
            "75%        0.761006\n",
            "max        1.704403\n",
            "Name: Total_happness_std, dtype: float64\n",
            "count    132.000000\n",
            "mean      -0.000054\n",
            "std        0.999972\n",
            "min       -0.951935\n",
            "25%       -0.951935\n",
            "50%       -0.951935\n",
            "75%        1.042481\n",
            "max        1.042481\n",
            "Name: Gender_std, dtype: float64\n",
            "count    132.000000\n",
            "mean      -0.000744\n",
            "std        1.000131\n",
            "min       -1.954074\n",
            "25%       -0.748100\n",
            "50%       -0.120872\n",
            "75%        0.600245\n",
            "max        3.290070\n",
            "Name: BMI_std, dtype: float64\n",
            "count    132.000000\n",
            "mean      -0.000744\n",
            "std        0.337772\n",
            "min       -0.624212\n",
            "25%       -0.233329\n",
            "50%        0.009580\n",
            "75%        0.193302\n",
            "max        1.179044\n",
            "Name: BMI_prediction, dtype: float64\n",
            "count    132.000000\n",
            "mean      26.066021\n",
            "std        1.807082\n",
            "min       22.730463\n",
            "25%       24.821688\n",
            "50%       26.121252\n",
            "75%       27.104166\n",
            "max       32.377887\n",
            "Name: BMI_prediction_BMI, dtype: float64\n",
            "count    132.000000\n",
            "mean       3.053030\n",
            "std        0.583676\n",
            "min        2.000000\n",
            "25%        3.000000\n",
            "50%        3.000000\n",
            "75%        3.000000\n",
            "max        4.000000\n",
            "Name: BMI_EVENT_Prediction, dtype: float64\n",
            "count       132\n",
            "unique        2\n",
            "top       FALSE\n",
            "freq         88\n",
            "Name: BMI_prediction_result, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYkPBMYNg7yH",
        "outputId": "0d442182-93cd-4b13-8d04-8745b27284cb"
      },
      "source": [
        "#特徴量をすべて出す\n",
        "for i in range(len(df.columns)):\n",
        "  print('{},'.format(df.columns[i]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start time,\n",
            "Village Name,\n",
            "Household ID,\n",
            "Household ID number,\n",
            "Number of people sharing the same pot,\n",
            "Husband full name,\n",
            "Age,\n",
            "Gender,\n",
            "Education level of husband,\n",
            "Major occupation of Husband,\n",
            "Fulltime farmer,\n",
            "Religious leader,\n",
            "Casual laborer,\n",
            "Civil servant,\n",
            "Business person,\n",
            "Student,\n",
            "Other (specify),\n",
            "Religion of Husband,\n",
            "Mobile phone,\n",
            "Bicycle,\n",
            "Motorbike,\n",
            "Car/truck,\n",
            "Radio / stereo,\n",
            "TV set or DVD,\n",
            "Satellite dish,\n",
            "Refrigerator,\n",
            "Own stand pipe,\n",
            "Own borehole/well,\n",
            "Own water tank,\n",
            "Access to shared well/borehole/stand pipe,\n",
            "Latrine/toilet,\n",
            "Other:,\n",
            "Wood,\n",
            "Charcoal,\n",
            "Biogas (stove),\n",
            "Electricity,\n",
            "Solar panel,\n",
            "Battery (large, e.g. car battery for power),\n",
            "Other:__1,\n",
            "Gas,\n",
            "Monthly income(Ksh),\n",
            "MIL,\n",
            "Gender__1,\n",
            "Number of cultivation field,\n",
            "walking min from your house to Wangige market?,\n",
            "walking min from your house to your favorite market,\n",
            "African nightshade_V,\n",
            "Amaranth_V,\n",
            "Apple local_F,\n",
            "Avocado_F,\n",
            "Banana_F,\n",
            "Beans_P,\n",
            "Beetroot_R,\n",
            "Broccoli_V,\n",
            "Cabbage_V,\n",
            "Carrot_V,\n",
            "Cassava_R,\n",
            "Chili pepper_S,\n",
            "Coco-yam_R,\n",
            "Coriander_S,\n",
            "Cowpeas_V,\n",
            "Cucumber_V,\n",
            "Custard apple_F,\n",
            "Edible gourd_V,\n",
            "Eggplant_V,\n",
            "Finger millet_C,\n",
            "French beans_P,\n",
            "Garden peas_P,\n",
            "Garlic_S,\n",
            "Ginger_S,\n",
            "Green grams_P,\n",
            "Green pepper_V,\n",
            "Guava_F,\n",
            "Karela_V,\n",
            "Kinaa_V,\n",
            "Lemon_F,\n",
            "Lettuce_V,\n",
            "Maize_C,\n",
            "Mango_F,\n",
            "Muu_V,\n",
            "Okra_V,\n",
            "Onion_V,\n",
            "Orange_F,\n",
            "Passion fruit_F,\n",
            "Pawpaw_F,\n",
            "Pearl millet_C,\n",
            "Pigeon peas_P,\n",
            "Pineapple_F,\n",
            "Potato_R,\n",
            "Pumpkin_V,\n",
            "Sorghum_C,\n",
            "Spinach_V,\n",
            "Sugarcane_SC,\n",
            "Sukuma(Kale)_V,\n",
            "Sweet potato_R,\n",
            "Tamarind_F,\n",
            "Tangerine_F,\n",
            "Tomato_V,\n",
            "Watermelon_V,\n",
            "White sapote_F,\n",
            "Cultivation diversity,\n",
            "Cultivation diversity_Cereals,\n",
            "Cultivation diversity_Root,\n",
            "Cultivation diversity_Suger,\n",
            "Cultivation diversity_Vegetable,\n",
            "Cultivation diversity_Palse,\n",
            "Cultivation diversity_Fruits,\n",
            "Cultivation diversity_Spice,\n",
            "Wild plant resources,\n",
            "African nightshade_V__1,\n",
            "Amaranth_V__1,\n",
            "Apple local_F__1,\n",
            "Avocado_F__1,\n",
            "Banana_F__1,\n",
            "Beans_P__1,\n",
            "Beetroot_R__1,\n",
            "Broccoli_V__1,\n",
            "Cabbage_V__1,\n",
            "Carrot_V__1,\n",
            "Cassava_R__1,\n",
            "Chili pepper_S__1,\n",
            "Coco-yam_R__1,\n",
            "Coriander_S__1,\n",
            "Cowpeas_V__1,\n",
            "Cucumber_V__1,\n",
            "Custard apple_F__1,\n",
            "Edible gourd_V__1,\n",
            "Eggplant_V__1,\n",
            "Finger millet_C__1,\n",
            "French beans_P__1,\n",
            "Garden peas_P__1,\n",
            "Garlic_S__1,\n",
            "Ginger_S__1,\n",
            "Green grams_P__1,\n",
            "Green pepper_V__1,\n",
            "Guava_F__1,\n",
            "Karela_V__1,\n",
            "Kinaa_V__1,\n",
            "Lemon_F__1,\n",
            "Lettuce_V__1,\n",
            "Maize_C__1,\n",
            "Mango_F__1,\n",
            "Muu_V__1,\n",
            "Okra_V__1,\n",
            "Onion_V__1,\n",
            "Orange_F__1,\n",
            "Passion fruit_F__1,\n",
            "Pawpaw_F__1,\n",
            "Pearl millet_C__1,\n",
            "Pigeon peas_P__1,\n",
            "Pineapple_F__1,\n",
            "Potato_R__1,\n",
            "Pumpkin_V__1,\n",
            "Sorghum_C__1,\n",
            "Spinach_V__1,\n",
            "Sugarcane_SC__1,\n",
            "Sukuma(Kale)_V__1,\n",
            "Sweet potato_R__1,\n",
            "Tamarind_F__1,\n",
            "Tangerine_F__1,\n",
            "Tomato_V__1,\n",
            "Watermelon_V__1,\n",
            "White sapote_F__1,\n",
            "Wild Diversity,\n",
            "Wild Diversity_Cereals,\n",
            "Wild Diversity_Root,\n",
            "Wild Diversity_Suger,\n",
            "Wild Diversity_Vegetable,\n",
            "Wild Diversity_Palse,\n",
            "Wild Diversity_Fruits,\n",
            "Wild Diversity_Spice,\n",
            "Animal Resources,\n",
            "Caw,\n",
            "Pig,\n",
            "Chiken,\n",
            "Rabbit,\n",
            "Snake,\n",
            "Goat,\n",
            "Sheep,\n",
            "Animal Diversity,\n",
            "Agrobiodiversity,\n",
            "Height(cm),\n",
            "Weight(kg),\n",
            "BMI,\n",
            "Waist(cm),\n",
            "Hip(cm),\n",
            "Ratio W/H,\n",
            "Body Fat (%),\n",
            "Systolic blood pressure(mmHg),\n",
            "Diastolic blood pressure(mmHg),\n",
            "Event_hypertension,\n",
            "Grasping power(kg),\n",
            "I feel cheerful and in good spirits,\n",
            "I feel calm and relaxed,\n",
            "I feel active and vigorous,\n",
            "I wake up feeling fresh and rested,\n",
            "My daily life is filled with things that interest me,\n",
            "Total_happness,\n",
            "Activity_level_2,\n",
            "Steps,\n",
            "percentage_production,\n",
            "Sleeping_time,\n",
            "Economics_time,\n",
            "Crop_time,\n",
            "Livestock_time,\n",
            "BMI_EVENT,\n",
            "Gender_replaced,\n",
            "Age_std,\n",
            "Agrobiodiversity_std,\n",
            "Steps_std,\n",
            "MIL_std,\n",
            "percentage_production_std,\n",
            "Total_happness_std,\n",
            "Gender_std,\n",
            "BMI_std,\n",
            "BMI_prediction,\n",
            "BMI_prediction_BMI,\n",
            "BMI_EVENT_Prediction,\n",
            "BMI_prediction_result,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s6In762Zvly"
      },
      "source": [
        "# #変数に入れてilocで任意の値を取得\n",
        "# Desc.iloc[:, 0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqlYtnt5j8q3"
      },
      "source": [
        "# for i in range(len(df.columns)):\n",
        "#   df[i].dtypes"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq4_OtmWaMRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296b5603-eb99-41b7-f2f4-5276794986aa"
      },
      "source": [
        "#for文でデータの確認\n",
        "for i in range(len(df.columns)):\n",
        "  print(df.iloc[:,i].dtypes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n",
            "object\n",
            "object\n",
            "int64\n",
            "int64\n",
            "object\n",
            "int64\n",
            "object\n",
            "object\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "float64\n",
            "object\n",
            "float64\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "int64\n",
            "int64\n",
            "object\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "int64\n",
            "int64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "float64\n",
            "int64\n",
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ov0bn37jJai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f92dd31-432e-410c-e220-93b3279f37e2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 132 entries, 0 to 131\n",
            "Columns: 219 entries, start time to BMI_prediction_result\n",
            "dtypes: float64(32), int64(173), object(14)\n",
            "memory usage: 226.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSpoeEHvlfdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3174d25-6c56-4ad1-e9e8-3357b0728ea0"
      },
      "source": [
        "df.value_counts"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.value_counts of                    start time  ... BMI_prediction_result\n",
              "0    2019-11-04T09:49:23+0000  ...                 FALSE\n",
              "1    2019-10-28T07:39:16+0000  ...                 FALSE\n",
              "2    2019-10-28T07:18:08+0000  ...                 FALSE\n",
              "3    2019-10-28T07:58:15+0000  ...                 FALSE\n",
              "4    2019-10-21T05:58:33+0000  ...                 FALSE\n",
              "..                        ...  ...                   ...\n",
              "127  2019-10-07T05:41:36+0000  ...                 FALSE\n",
              "128  2019-10-28T07:58:15+0000  ...                 FALSE\n",
              "129  2019-10-07T06:17:02+0000  ...                  TURE\n",
              "130  2019-11-11T06:39:32+0000  ...                  TURE\n",
              "131  2019-09-23T06:21:35+0000  ...                  TURE\n",
              "\n",
              "[132 rows x 219 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BowX9iONloih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "b09768af-bd70-41e5-deea-b0a2eb206d1e"
      },
      "source": [
        "df.isnull()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start time</th>\n",
              "      <th>Village Name</th>\n",
              "      <th>Household ID</th>\n",
              "      <th>Household ID number</th>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <th>Husband full name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Education level of husband</th>\n",
              "      <th>Major occupation of Husband</th>\n",
              "      <th>Fulltime farmer</th>\n",
              "      <th>Religious leader</th>\n",
              "      <th>Casual laborer</th>\n",
              "      <th>Civil servant</th>\n",
              "      <th>Business person</th>\n",
              "      <th>Student</th>\n",
              "      <th>Other (specify)</th>\n",
              "      <th>Religion of Husband</th>\n",
              "      <th>Mobile phone</th>\n",
              "      <th>Bicycle</th>\n",
              "      <th>Motorbike</th>\n",
              "      <th>Car/truck</th>\n",
              "      <th>Radio / stereo</th>\n",
              "      <th>TV set or DVD</th>\n",
              "      <th>Satellite dish</th>\n",
              "      <th>Refrigerator</th>\n",
              "      <th>Own stand pipe</th>\n",
              "      <th>Own borehole/well</th>\n",
              "      <th>Own water tank</th>\n",
              "      <th>Access to shared well/borehole/stand pipe</th>\n",
              "      <th>Latrine/toilet</th>\n",
              "      <th>Other:</th>\n",
              "      <th>Wood</th>\n",
              "      <th>Charcoal</th>\n",
              "      <th>Biogas (stove)</th>\n",
              "      <th>Electricity</th>\n",
              "      <th>Solar panel</th>\n",
              "      <th>Battery (large, e.g. car battery for power)</th>\n",
              "      <th>Other:__1</th>\n",
              "      <th>Gas</th>\n",
              "      <th>...</th>\n",
              "      <th>Animal Diversity</th>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <th>Height(cm)</th>\n",
              "      <th>Weight(kg)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Waist(cm)</th>\n",
              "      <th>Hip(cm)</th>\n",
              "      <th>Ratio W/H</th>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <th>Event_hypertension</th>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <th>I feel cheerful and in good spirits</th>\n",
              "      <th>I feel calm and relaxed</th>\n",
              "      <th>I feel active and vigorous</th>\n",
              "      <th>I wake up feeling fresh and rested</th>\n",
              "      <th>My daily life is filled with things that interest me</th>\n",
              "      <th>Total_happness</th>\n",
              "      <th>Activity_level_2</th>\n",
              "      <th>Steps</th>\n",
              "      <th>percentage_production</th>\n",
              "      <th>Sleeping_time</th>\n",
              "      <th>Economics_time</th>\n",
              "      <th>Crop_time</th>\n",
              "      <th>Livestock_time</th>\n",
              "      <th>BMI_EVENT</th>\n",
              "      <th>Gender_replaced</th>\n",
              "      <th>Age_std</th>\n",
              "      <th>Agrobiodiversity_std</th>\n",
              "      <th>Steps_std</th>\n",
              "      <th>MIL_std</th>\n",
              "      <th>percentage_production_std</th>\n",
              "      <th>Total_happness_std</th>\n",
              "      <th>Gender_std</th>\n",
              "      <th>BMI_std</th>\n",
              "      <th>BMI_prediction</th>\n",
              "      <th>BMI_prediction_BMI</th>\n",
              "      <th>BMI_EVENT_Prediction</th>\n",
              "      <th>BMI_prediction_result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 219 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     start time  Village Name  ...  BMI_EVENT_Prediction  BMI_prediction_result\n",
              "0         False         False  ...                 False                  False\n",
              "1         False         False  ...                 False                  False\n",
              "2         False         False  ...                 False                  False\n",
              "3         False         False  ...                 False                  False\n",
              "4         False         False  ...                 False                  False\n",
              "..          ...           ...  ...                   ...                    ...\n",
              "127       False         False  ...                 False                  False\n",
              "128       False         False  ...                 False                  False\n",
              "129       False         False  ...                 False                  False\n",
              "130       False         False  ...                 False                  False\n",
              "131       False         False  ...                 False                  False\n",
              "\n",
              "[132 rows x 219 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugkpru11P63n"
      },
      "source": [
        "特徴量の選択：\n",
        "Number of people sharing the same pot,\n",
        "Age,\n",
        "Gender,\n",
        "Education level of husband,\n",
        "MIL,\n",
        "Gender__1,\n",
        "Number of cultivation field,\n",
        "walking min from your house to Wangige market?,\n",
        "Cultivation diversity,\n",
        "Cultivation diversity_Cereals,\n",
        "Cultivation diversity_Root,\n",
        "Cultivation diversity_Suger,\n",
        "Cultivation diversity_Vegetable,\n",
        "Cultivation diversity_Palse,\n",
        "Cultivation diversity_Fruits,\n",
        "Cultivation diversity_Spice,\n",
        "Wild Diversity,\n",
        "Wild Diversity_Cereals,\n",
        "Wild Diversity_Root,\n",
        "Wild Diversity_Suger,\n",
        "Wild Diversity_Vegetable,\n",
        "Wild Diversity_Palse,\n",
        "Wild Diversity_Fruits,\n",
        "Wild Diversity_Spice,\n",
        "Animal Diversity,\n",
        "Agrobiodiversity,\n",
        "Height(cm),\n",
        "Weight(kg),\n",
        "BMI,\n",
        "Waist(cm),\n",
        "Hip(cm),\n",
        "Ratio W/H,\n",
        "Body Fat (%),\n",
        "Systolic blood pressure(mmHg),\n",
        "Diastolic blood pressure(mmHg),\n",
        "Event_hypertension,\n",
        "Grasping power(kg),\n",
        "Total_happness,\n",
        "Activity_level_2,\n",
        "Steps,\n",
        "percentage_production,\n",
        "Sleeping_time,\n",
        "Economics_time,\n",
        "Crop_time,\n",
        "Livestock_time,\n",
        "BMI_EVENT,\n",
        "Gender_replaced,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw-is6Odlt-a"
      },
      "source": [
        "#Statsmodelを用いて"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbJBdu7Gq1nf"
      },
      "source": [
        "参考文献：https://tanuhack.com/statsmodels-multiple-lra/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwbqY20fq3d9"
      },
      "source": [
        "df_features = df[['Household ID',\n",
        "'Household ID number',\n",
        "'Number of people sharing the same pot',\n",
        "'Age',\n",
        "'Gender',\n",
        "'Education level of husband',\n",
        "'MIL',\n",
        "'Number of cultivation field',\n",
        "'walking min from your house to Wangige market?',\n",
        "'Cultivation diversity',\n",
        "'Cultivation diversity_Cereals',\n",
        "'Cultivation diversity_Root',\n",
        "'Cultivation diversity_Suger',\n",
        "'Cultivation diversity_Vegetable',\n",
        "'Cultivation diversity_Palse',\n",
        "'Cultivation diversity_Fruits',\n",
        "'Cultivation diversity_Spice',\n",
        "'Wild Diversity',\n",
        "'Wild Diversity_Cereals',\n",
        "'Wild Diversity_Root',\n",
        "'Wild Diversity_Suger',\n",
        "'Wild Diversity_Vegetable',\n",
        "'Wild Diversity_Palse',\n",
        "'Wild Diversity_Fruits',\n",
        "'Wild Diversity_Spice',\n",
        "'Animal Diversity',\n",
        "'Agrobiodiversity',\n",
        "'Height(cm)',\n",
        "'Weight(kg)',\n",
        "'BMI',\n",
        "'Waist(cm)',\n",
        "'Hip(cm)',\n",
        "'Ratio W/H',\n",
        "'Body Fat (%)',\n",
        "'Systolic blood pressure(mmHg)',\n",
        "'Diastolic blood pressure(mmHg)',\n",
        "'Event_hypertension',\n",
        "'Grasping power(kg)',\n",
        "'Total_happness',\n",
        "'Activity_level_2',\n",
        "'Steps',\n",
        "'percentage_production',\n",
        "'Sleeping_time',\n",
        "'Economics_time',\n",
        "'Crop_time',\n",
        "'Livestock_time',\n",
        "'BMI_EVENT',\n",
        "'Gender_replaced']]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_z367q9fvOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "8bf44b95-41b9-42de-f217-484e93f6ac40"
      },
      "source": [
        "df_features"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Household ID</th>\n",
              "      <th>Household ID number</th>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Education level of husband</th>\n",
              "      <th>MIL</th>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <th>Cultivation diversity</th>\n",
              "      <th>Cultivation diversity_Cereals</th>\n",
              "      <th>Cultivation diversity_Root</th>\n",
              "      <th>Cultivation diversity_Suger</th>\n",
              "      <th>Cultivation diversity_Vegetable</th>\n",
              "      <th>Cultivation diversity_Palse</th>\n",
              "      <th>Cultivation diversity_Fruits</th>\n",
              "      <th>Cultivation diversity_Spice</th>\n",
              "      <th>Wild Diversity</th>\n",
              "      <th>Wild Diversity_Cereals</th>\n",
              "      <th>Wild Diversity_Root</th>\n",
              "      <th>Wild Diversity_Suger</th>\n",
              "      <th>Wild Diversity_Vegetable</th>\n",
              "      <th>Wild Diversity_Palse</th>\n",
              "      <th>Wild Diversity_Fruits</th>\n",
              "      <th>Wild Diversity_Spice</th>\n",
              "      <th>Animal Diversity</th>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <th>Height(cm)</th>\n",
              "      <th>Weight(kg)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Waist(cm)</th>\n",
              "      <th>Hip(cm)</th>\n",
              "      <th>Ratio W/H</th>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <th>Event_hypertension</th>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <th>Total_happness</th>\n",
              "      <th>Activity_level_2</th>\n",
              "      <th>Steps</th>\n",
              "      <th>percentage_production</th>\n",
              "      <th>Sleeping_time</th>\n",
              "      <th>Economics_time</th>\n",
              "      <th>Crop_time</th>\n",
              "      <th>Livestock_time</th>\n",
              "      <th>BMI_EVENT</th>\n",
              "      <th>Gender_replaced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muthumu/ Kangora</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>M</td>\n",
              "      <td>college/university</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>147</td>\n",
              "      <td>57.0</td>\n",
              "      <td>26.377898</td>\n",
              "      <td>78.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.886364</td>\n",
              "      <td>23.0</td>\n",
              "      <td>120</td>\n",
              "      <td>91</td>\n",
              "      <td>Yes</td>\n",
              "      <td>34.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>13055.00000</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>43</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>164</td>\n",
              "      <td>61.6</td>\n",
              "      <td>22.903034</td>\n",
              "      <td>74.0</td>\n",
              "      <td>100.5</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>32.5</td>\n",
              "      <td>121</td>\n",
              "      <td>85</td>\n",
              "      <td>No</td>\n",
              "      <td>29.4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>16256.00000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>150</td>\n",
              "      <td>68.4</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>95.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.887850</td>\n",
              "      <td>42.4</td>\n",
              "      <td>126</td>\n",
              "      <td>69</td>\n",
              "      <td>No</td>\n",
              "      <td>24.2</td>\n",
              "      <td>23.0</td>\n",
              "      <td>153.300000</td>\n",
              "      <td>15457.00000</td>\n",
              "      <td>22.700000</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>college/university</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>155</td>\n",
              "      <td>79.5</td>\n",
              "      <td>33.090531</td>\n",
              "      <td>108.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>1.009346</td>\n",
              "      <td>42.7</td>\n",
              "      <td>140</td>\n",
              "      <td>93</td>\n",
              "      <td>Yes</td>\n",
              "      <td>48.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.600000</td>\n",
              "      <td>14941.00000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gababa</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>164</td>\n",
              "      <td>57.1</td>\n",
              "      <td>21.229923</td>\n",
              "      <td>74.5</td>\n",
              "      <td>96.5</td>\n",
              "      <td>0.772021</td>\n",
              "      <td>23.3</td>\n",
              "      <td>128</td>\n",
              "      <td>83</td>\n",
              "      <td>No</td>\n",
              "      <td>12.6</td>\n",
              "      <td>19.0</td>\n",
              "      <td>59.500000</td>\n",
              "      <td>8583.50000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>Gatathuthua</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>167</td>\n",
              "      <td>81.7</td>\n",
              "      <td>29.294704</td>\n",
              "      <td>116.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.991453</td>\n",
              "      <td>38.5</td>\n",
              "      <td>117</td>\n",
              "      <td>79</td>\n",
              "      <td>No</td>\n",
              "      <td>25.9</td>\n",
              "      <td>17.0</td>\n",
              "      <td>51.333333</td>\n",
              "      <td>11640.33333</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>M</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>154</td>\n",
              "      <td>62.0</td>\n",
              "      <td>26.142688</td>\n",
              "      <td>92.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.910891</td>\n",
              "      <td>24.0</td>\n",
              "      <td>121</td>\n",
              "      <td>79</td>\n",
              "      <td>No</td>\n",
              "      <td>34.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>20066.00000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>Kangora</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>59</td>\n",
              "      <td>M</td>\n",
              "      <td>secondary school</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>166</td>\n",
              "      <td>58.8</td>\n",
              "      <td>21.338366</td>\n",
              "      <td>85.5</td>\n",
              "      <td>94.5</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>22.9</td>\n",
              "      <td>139</td>\n",
              "      <td>97</td>\n",
              "      <td>Yes</td>\n",
              "      <td>38.6</td>\n",
              "      <td>19.0</td>\n",
              "      <td>81.909867</td>\n",
              "      <td>13765.47333</td>\n",
              "      <td>24.285714</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>Wangige</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>primary school</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>185</td>\n",
              "      <td>70.9</td>\n",
              "      <td>20.715851</td>\n",
              "      <td>85.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>13.7</td>\n",
              "      <td>139</td>\n",
              "      <td>87</td>\n",
              "      <td>No</td>\n",
              "      <td>48.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>81.909867</td>\n",
              "      <td>13765.47333</td>\n",
              "      <td>38.195515</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>Kiiniki</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>42</td>\n",
              "      <td>F</td>\n",
              "      <td>primary school</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>161</td>\n",
              "      <td>70.9</td>\n",
              "      <td>27.352340</td>\n",
              "      <td>96.5</td>\n",
              "      <td>112.5</td>\n",
              "      <td>0.857778</td>\n",
              "      <td>36.5</td>\n",
              "      <td>119</td>\n",
              "      <td>93</td>\n",
              "      <td>Yes</td>\n",
              "      <td>36.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>36610.00000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Household ID  Household ID number  ...  BMI_EVENT  Gender_replaced\n",
              "0    Muthumu/ Kangora                    2  ...          3                1\n",
              "1             Muthumu                    3  ...          2                0\n",
              "2             Muthumu                    2  ...          4                0\n",
              "3             Muthumu                    4  ...          4                0\n",
              "4              Gababa                    5  ...          2                0\n",
              "..                ...                  ...  ...        ...              ...\n",
              "127       Gatathuthua                    5  ...          4                0\n",
              "128           Muthumu                    4  ...          3                1\n",
              "129           Kangora                    1  ...          2                1\n",
              "130           Wangige                    2  ...          2                1\n",
              "131           Kiiniki                    3  ...          3                0\n",
              "\n",
              "[132 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASaJIMn2gUpD"
      },
      "source": [
        "df_time_consuption = df.loc[:, ['Household ID',\n",
        "'Household ID number',\n",
        "'Sleeping_time',\n",
        "'Economics_time',\n",
        "'Crop_time',\n",
        "'Livestock_time']]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cQyvFWUg6-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f3810e8d-fefd-4698-a6cf-3674e9abbf65"
      },
      "source": [
        "df_time_consuption"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Household ID</th>\n",
              "      <th>Household ID number</th>\n",
              "      <th>Sleeping_time</th>\n",
              "      <th>Economics_time</th>\n",
              "      <th>Crop_time</th>\n",
              "      <th>Livestock_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Muthumu/ Kangora</td>\n",
              "      <td>2</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>3</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>120.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>2</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gababa</td>\n",
              "      <td>5</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>Gatathuthua</td>\n",
              "      <td>5</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Muthumu</td>\n",
              "      <td>4</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>Kangora</td>\n",
              "      <td>1</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>120.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>Wangige</td>\n",
              "      <td>2</td>\n",
              "      <td>510.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>Kiiniki</td>\n",
              "      <td>3</td>\n",
              "      <td>530.842105</td>\n",
              "      <td>392.526316</td>\n",
              "      <td>272.210526</td>\n",
              "      <td>49.263158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Household ID  Household ID number  ...   Crop_time  Livestock_time\n",
              "0    Muthumu/ Kangora                    2  ...  390.000000       90.000000\n",
              "1             Muthumu                    3  ...  270.000000      120.000000\n",
              "2             Muthumu                    2  ...  210.000000        0.000000\n",
              "3             Muthumu                    4  ...  272.210526       49.263158\n",
              "4              Gababa                    5  ...  480.000000        0.000000\n",
              "..                ...                  ...  ...         ...             ...\n",
              "127       Gatathuthua                    5  ...  272.210526       49.263158\n",
              "128           Muthumu                    4  ...  272.210526       49.263158\n",
              "129           Kangora                    1  ...   90.000000      120.000000\n",
              "130           Wangige                    2  ...    0.000000        0.000000\n",
              "131           Kiiniki                    3  ...  272.210526       49.263158\n",
              "\n",
              "[132 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgSk4fKHikqA"
      },
      "source": [
        "StatsModelsモジュールの使い方\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_eMt830g8mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f911254-da46-4038-fb3b-dc8d746c0541"
      },
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owuv5AstipPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc09cf32-f26a-4b04-f72b-4df55edcd10f"
      },
      "source": [
        "!pip install statsmodels"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.0->statsmodels) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lop2fPAhiw9p"
      },
      "source": [
        "# get_dummies()で質的データも対応可能\n",
        "\n",
        "x = df[[\n",
        "'Number of people sharing the same pot',\n",
        "'Age',\n",
        "'MIL',\n",
        "'Number of cultivation field',\n",
        "'walking min from your house to Wangige market?',\n",
        "'Cultivation diversity',\n",
        "'Cultivation diversity_Cereals',\n",
        "'Cultivation diversity_Root',\n",
        "'Cultivation diversity_Suger',\n",
        "'Cultivation diversity_Vegetable',\n",
        "'Cultivation diversity_Palse',\n",
        "'Cultivation diversity_Fruits',\n",
        "'Cultivation diversity_Spice',\n",
        "'Wild Diversity',\n",
        "'Wild Diversity_Cereals',\n",
        "'Wild Diversity_Root',\n",
        "'Wild Diversity_Suger',\n",
        "'Wild Diversity_Vegetable',\n",
        "'Wild Diversity_Palse',\n",
        "'Wild Diversity_Fruits',\n",
        "'Wild Diversity_Spice',\n",
        "'Animal Diversity',\n",
        "'Agrobiodiversity',\n",
        "'Height(cm)',\n",
        "'Weight(kg)',\n",
        "'BMI',\n",
        "'Waist(cm)',\n",
        "'Hip(cm)',\n",
        "'Ratio W/H',\n",
        "'Body Fat (%)',\n",
        "'Systolic blood pressure(mmHg)',\n",
        "'Diastolic blood pressure(mmHg)',\n",
        "'Grasping power(kg)',\n",
        "'Total_happness',\n",
        "'Activity_level_2',\n",
        "'Steps',\n",
        "'percentage_production',\n",
        "'Sleeping_time',\n",
        "'Economics_time',\n",
        "'Crop_time',\n",
        "'Livestock_time',\n",
        "'Gender_replaced']]\n",
        "\n",
        "\n",
        "y = df['BMI_EVENT']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuJmnmrhY6RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf42d9b-e42c-44b8-e6e5-98d2fdc12c7e"
      },
      "source": [
        "x\n",
        "x.dtypes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Number of people sharing the same pot               int64\n",
              "Age                                                 int64\n",
              "MIL                                               float64\n",
              "Number of cultivation field                         int64\n",
              "walking min from your house to Wangige market?      int64\n",
              "Cultivation diversity                               int64\n",
              "Cultivation diversity_Cereals                       int64\n",
              "Cultivation diversity_Root                          int64\n",
              "Cultivation diversity_Suger                         int64\n",
              "Cultivation diversity_Vegetable                     int64\n",
              "Cultivation diversity_Palse                         int64\n",
              "Cultivation diversity_Fruits                        int64\n",
              "Cultivation diversity_Spice                         int64\n",
              "Wild Diversity                                      int64\n",
              "Wild Diversity_Cereals                              int64\n",
              "Wild Diversity_Root                                 int64\n",
              "Wild Diversity_Suger                                int64\n",
              "Wild Diversity_Vegetable                            int64\n",
              "Wild Diversity_Palse                                int64\n",
              "Wild Diversity_Fruits                               int64\n",
              "Wild Diversity_Spice                                int64\n",
              "Animal Diversity                                    int64\n",
              "Agrobiodiversity                                    int64\n",
              "Height(cm)                                          int64\n",
              "Weight(kg)                                        float64\n",
              "BMI                                               float64\n",
              "Waist(cm)                                         float64\n",
              "Hip(cm)                                           float64\n",
              "Ratio W/H                                         float64\n",
              "Body Fat (%)                                      float64\n",
              "Systolic blood pressure(mmHg)                       int64\n",
              "Diastolic blood pressure(mmHg)                      int64\n",
              "Grasping power(kg)                                float64\n",
              "Total_happness                                    float64\n",
              "Activity_level_2                                  float64\n",
              "Steps                                             float64\n",
              "percentage_production                             float64\n",
              "Sleeping_time                                     float64\n",
              "Economics_time                                    float64\n",
              "Crop_time                                         float64\n",
              "Livestock_time                                    float64\n",
              "Gender_replaced                                     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbexR7g2kMvQ"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NXCU5MDhOK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad68d179-1e73-49cf-dc0f-30cbbba3c62d"
      },
      "source": [
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      3\n",
              "1      2\n",
              "2      4\n",
              "3      4\n",
              "4      2\n",
              "      ..\n",
              "127    4\n",
              "128    3\n",
              "129    2\n",
              "130    2\n",
              "131    3\n",
              "Name: BMI_EVENT, Length: 132, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U56fMWncW1tz"
      },
      "source": [
        "x_nparray = np.array(x)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNKYXGUYYo8_"
      },
      "source": [
        "y_nparray = np.array(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_rOZp63WyWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bc3e7f-e840-4da4-d8c5-91c3059ba241"
      },
      "source": [
        "# 定数項(y切片)を必要とする線形回帰のモデル式ならば必須\n",
        "X = sm.add_constant(x.astype(float))\n",
        "print(X)\n",
        "\n",
        "# 最小二乗法でモデル化\n",
        "model = sm.OLS(y.astype(float), X)\n",
        "result = model.fit()\n",
        "\n",
        "# 重回帰分析の結果を表示\n",
        "result.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     const  ...  Gender_replaced\n",
            "0      1.0  ...              1.0\n",
            "1      1.0  ...              0.0\n",
            "2      1.0  ...              0.0\n",
            "3      1.0  ...              0.0\n",
            "4      1.0  ...              0.0\n",
            "..     ...  ...              ...\n",
            "127    1.0  ...              0.0\n",
            "128    1.0  ...              1.0\n",
            "129    1.0  ...              1.0\n",
            "130    1.0  ...              1.0\n",
            "131    1.0  ...              0.0\n",
            "\n",
            "[132 rows x 43 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>BMI_EVENT</td>    <th>  R-squared:         </th> <td>   0.684</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.559</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.492</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 05 May 2021</td> <th>  Prob (F-statistic):</th> <td>1.30e-11</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>04:21:38</td>     <th>  Log-Likelihood:    </th> <td> -101.49</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   132</td>      <th>  AIC:               </th> <td>   279.0</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    94</td>      <th>  BIC:               </th> <td>   388.5</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    37</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "                         <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>                                          <td>   -4.2554</td> <td>   10.046</td> <td>   -0.424</td> <td> 0.673</td> <td>  -24.202</td> <td>   15.691</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of people sharing the same pot</th>          <td>   -0.0088</td> <td>    0.050</td> <td>   -0.176</td> <td> 0.861</td> <td>   -0.108</td> <td>    0.091</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Age</th>                                            <td>   -0.0075</td> <td>    0.008</td> <td>   -0.892</td> <td> 0.374</td> <td>   -0.024</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MIL</th>                                            <td>    0.0081</td> <td>    0.033</td> <td>    0.245</td> <td> 0.807</td> <td>   -0.058</td> <td>    0.074</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of cultivation field</th>                    <td>    0.1102</td> <td>    0.116</td> <td>    0.953</td> <td> 0.343</td> <td>   -0.119</td> <td>    0.340</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>walking min from your house to Wangige market?</th> <td>   -0.0052</td> <td>    0.008</td> <td>   -0.668</td> <td> 0.506</td> <td>   -0.021</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity</th>                          <td>    0.1877</td> <td>    0.452</td> <td>    0.415</td> <td> 0.679</td> <td>   -0.710</td> <td>    1.086</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Cereals</th>                  <td>   -0.1093</td> <td>    0.655</td> <td>   -0.167</td> <td> 0.868</td> <td>   -1.409</td> <td>    1.190</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Root</th>                     <td>   -0.2354</td> <td>    0.624</td> <td>   -0.377</td> <td> 0.707</td> <td>   -1.475</td> <td>    1.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Suger</th>                    <td>   -0.2906</td> <td>    0.585</td> <td>   -0.497</td> <td> 0.621</td> <td>   -1.452</td> <td>    0.871</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Vegetable</th>                <td>   -0.2829</td> <td>    0.606</td> <td>   -0.467</td> <td> 0.642</td> <td>   -1.486</td> <td>    0.921</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Palse</th>                    <td>   -0.2872</td> <td>    0.623</td> <td>   -0.461</td> <td> 0.646</td> <td>   -1.523</td> <td>    0.949</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Fruits</th>                   <td>   -0.0725</td> <td>    0.625</td> <td>   -0.116</td> <td> 0.908</td> <td>   -1.314</td> <td>    1.169</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cultivation diversity_Spice</th>                    <td>   -0.1756</td> <td>    0.616</td> <td>   -0.285</td> <td> 0.776</td> <td>   -1.399</td> <td>    1.047</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity</th>                                 <td>   -0.0832</td> <td>    0.166</td> <td>   -0.503</td> <td> 0.616</td> <td>   -0.412</td> <td>    0.245</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Cereals</th>                         <td> 7.704e-14</td> <td> 5.73e-14</td> <td>    1.344</td> <td> 0.182</td> <td>-3.68e-14</td> <td> 1.91e-13</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Root</th>                            <td> 1.272e-14</td> <td> 1.27e-14</td> <td>    1.001</td> <td> 0.319</td> <td>-1.25e-14</td> <td> 3.79e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Suger</th>                           <td>    0.1618</td> <td>    0.234</td> <td>    0.692</td> <td> 0.490</td> <td>   -0.302</td> <td>    0.626</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Vegetable</th>                       <td>    0.0749</td> <td>    0.201</td> <td>    0.373</td> <td> 0.710</td> <td>   -0.323</td> <td>    0.473</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Palse</th>                           <td>-5.302e-14</td> <td> 4.41e-14</td> <td>   -1.202</td> <td> 0.232</td> <td>-1.41e-13</td> <td> 3.46e-14</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Fruits</th>                          <td>   -0.0978</td> <td>    0.145</td> <td>   -0.674</td> <td> 0.502</td> <td>   -0.386</td> <td>    0.190</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Wild Diversity_Spice</th>                           <td>   -0.2221</td> <td>    0.439</td> <td>   -0.505</td> <td> 0.614</td> <td>   -1.095</td> <td>    0.651</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Animal Diversity</th>                               <td>   -0.0535</td> <td>    0.159</td> <td>   -0.335</td> <td> 0.738</td> <td>   -0.370</td> <td>    0.263</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Agrobiodiversity</th>                               <td>    0.0509</td> <td>    0.162</td> <td>    0.315</td> <td> 0.753</td> <td>   -0.270</td> <td>    0.372</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Height(cm)</th>                                     <td>   -0.0283</td> <td>    0.044</td> <td>   -0.649</td> <td> 0.518</td> <td>   -0.115</td> <td>    0.058</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Weight(kg)</th>                                     <td>    0.0342</td> <td>    0.051</td> <td>    0.675</td> <td> 0.501</td> <td>   -0.066</td> <td>    0.135</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>BMI</th>                                            <td>    0.0492</td> <td>    0.137</td> <td>    0.360</td> <td> 0.720</td> <td>   -0.222</td> <td>    0.321</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Waist(cm)</th>                                      <td>   -0.0893</td> <td>    0.067</td> <td>   -1.336</td> <td> 0.185</td> <td>   -0.222</td> <td>    0.043</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Hip(cm)</th>                                        <td>    0.0796</td> <td>    0.059</td> <td>    1.342</td> <td> 0.183</td> <td>   -0.038</td> <td>    0.197</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Ratio W/H</th>                                      <td>    9.1372</td> <td>    6.853</td> <td>    1.333</td> <td> 0.186</td> <td>   -4.470</td> <td>   22.744</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Body Fat (%)</th>                                   <td>    0.0055</td> <td>    0.009</td> <td>    0.620</td> <td> 0.537</td> <td>   -0.012</td> <td>    0.023</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Systolic blood pressure(mmHg)</th>                  <td>    0.0021</td> <td>    0.005</td> <td>    0.411</td> <td> 0.682</td> <td>   -0.008</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Diastolic blood pressure(mmHg)</th>                 <td>    0.0038</td> <td>    0.008</td> <td>    0.453</td> <td> 0.652</td> <td>   -0.013</td> <td>    0.020</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Grasping power(kg)</th>                             <td>    0.0029</td> <td>    0.009</td> <td>    0.324</td> <td> 0.747</td> <td>   -0.015</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total_happness</th>                                 <td>   -0.0237</td> <td>    0.020</td> <td>   -1.197</td> <td> 0.234</td> <td>   -0.063</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Activity_level_2</th>                               <td>    0.0012</td> <td>    0.001</td> <td>    0.962</td> <td> 0.339</td> <td>   -0.001</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Steps</th>                                          <td>-1.361e-05</td> <td> 1.09e-05</td> <td>   -1.250</td> <td> 0.214</td> <td>-3.52e-05</td> <td>    8e-06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>percentage_production</th>                          <td> 8.628e-05</td> <td>    0.005</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.009</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sleeping_time</th>                                  <td>   -0.0002</td> <td>    0.001</td> <td>   -0.240</td> <td> 0.811</td> <td>   -0.002</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Economics_time</th>                                 <td>    0.0011</td> <td>    0.001</td> <td>    2.076</td> <td> 0.041</td> <td> 4.76e-05</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Crop_time</th>                                      <td>   -0.0008</td> <td>    0.001</td> <td>   -1.406</td> <td> 0.163</td> <td>   -0.002</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Livestock_time</th>                                 <td>   -0.0002</td> <td>    0.001</td> <td>   -0.156</td> <td> 0.877</td> <td>   -0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Gender_replaced</th>                                <td>    0.1820</td> <td>    0.197</td> <td>    0.923</td> <td> 0.359</td> <td>   -0.210</td> <td>    0.573</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>10.701</td> <th>  Durbin-Watson:     </th> <td>   1.938</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.005</td> <th>  Jarque-Bera (JB):  </th> <td>  10.926</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.681</td> <th>  Prob(JB):          </th> <td> 0.00424</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.365</td> <th>  Cond. No.          </th> <td>1.17e+16</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.51e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              BMI_EVENT   R-squared:                       0.684\n",
              "Model:                            OLS   Adj. R-squared:                  0.559\n",
              "Method:                 Least Squares   F-statistic:                     5.492\n",
              "Date:                Wed, 05 May 2021   Prob (F-statistic):           1.30e-11\n",
              "Time:                        04:21:38   Log-Likelihood:                -101.49\n",
              "No. Observations:                 132   AIC:                             279.0\n",
              "Df Residuals:                      94   BIC:                             388.5\n",
              "Df Model:                          37                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==================================================================================================================\n",
              "                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------------------------------------------\n",
              "const                                             -4.2554     10.046     -0.424      0.673     -24.202      15.691\n",
              "Number of people sharing the same pot             -0.0088      0.050     -0.176      0.861      -0.108       0.091\n",
              "Age                                               -0.0075      0.008     -0.892      0.374      -0.024       0.009\n",
              "MIL                                                0.0081      0.033      0.245      0.807      -0.058       0.074\n",
              "Number of cultivation field                        0.1102      0.116      0.953      0.343      -0.119       0.340\n",
              "walking min from your house to Wangige market?    -0.0052      0.008     -0.668      0.506      -0.021       0.010\n",
              "Cultivation diversity                              0.1877      0.452      0.415      0.679      -0.710       1.086\n",
              "Cultivation diversity_Cereals                     -0.1093      0.655     -0.167      0.868      -1.409       1.190\n",
              "Cultivation diversity_Root                        -0.2354      0.624     -0.377      0.707      -1.475       1.004\n",
              "Cultivation diversity_Suger                       -0.2906      0.585     -0.497      0.621      -1.452       0.871\n",
              "Cultivation diversity_Vegetable                   -0.2829      0.606     -0.467      0.642      -1.486       0.921\n",
              "Cultivation diversity_Palse                       -0.2872      0.623     -0.461      0.646      -1.523       0.949\n",
              "Cultivation diversity_Fruits                      -0.0725      0.625     -0.116      0.908      -1.314       1.169\n",
              "Cultivation diversity_Spice                       -0.1756      0.616     -0.285      0.776      -1.399       1.047\n",
              "Wild Diversity                                    -0.0832      0.166     -0.503      0.616      -0.412       0.245\n",
              "Wild Diversity_Cereals                          7.704e-14   5.73e-14      1.344      0.182   -3.68e-14    1.91e-13\n",
              "Wild Diversity_Root                             1.272e-14   1.27e-14      1.001      0.319   -1.25e-14    3.79e-14\n",
              "Wild Diversity_Suger                               0.1618      0.234      0.692      0.490      -0.302       0.626\n",
              "Wild Diversity_Vegetable                           0.0749      0.201      0.373      0.710      -0.323       0.473\n",
              "Wild Diversity_Palse                           -5.302e-14   4.41e-14     -1.202      0.232   -1.41e-13    3.46e-14\n",
              "Wild Diversity_Fruits                             -0.0978      0.145     -0.674      0.502      -0.386       0.190\n",
              "Wild Diversity_Spice                              -0.2221      0.439     -0.505      0.614      -1.095       0.651\n",
              "Animal Diversity                                  -0.0535      0.159     -0.335      0.738      -0.370       0.263\n",
              "Agrobiodiversity                                   0.0509      0.162      0.315      0.753      -0.270       0.372\n",
              "Height(cm)                                        -0.0283      0.044     -0.649      0.518      -0.115       0.058\n",
              "Weight(kg)                                         0.0342      0.051      0.675      0.501      -0.066       0.135\n",
              "BMI                                                0.0492      0.137      0.360      0.720      -0.222       0.321\n",
              "Waist(cm)                                         -0.0893      0.067     -1.336      0.185      -0.222       0.043\n",
              "Hip(cm)                                            0.0796      0.059      1.342      0.183      -0.038       0.197\n",
              "Ratio W/H                                          9.1372      6.853      1.333      0.186      -4.470      22.744\n",
              "Body Fat (%)                                       0.0055      0.009      0.620      0.537      -0.012       0.023\n",
              "Systolic blood pressure(mmHg)                      0.0021      0.005      0.411      0.682      -0.008       0.012\n",
              "Diastolic blood pressure(mmHg)                     0.0038      0.008      0.453      0.652      -0.013       0.020\n",
              "Grasping power(kg)                                 0.0029      0.009      0.324      0.747      -0.015       0.021\n",
              "Total_happness                                    -0.0237      0.020     -1.197      0.234      -0.063       0.016\n",
              "Activity_level_2                                   0.0012      0.001      0.962      0.339      -0.001       0.004\n",
              "Steps                                          -1.361e-05   1.09e-05     -1.250      0.214   -3.52e-05       8e-06\n",
              "percentage_production                           8.628e-05      0.005      0.018      0.986      -0.009       0.010\n",
              "Sleeping_time                                     -0.0002      0.001     -0.240      0.811      -0.002       0.001\n",
              "Economics_time                                     0.0011      0.001      2.076      0.041    4.76e-05       0.002\n",
              "Crop_time                                         -0.0008      0.001     -1.406      0.163      -0.002       0.000\n",
              "Livestock_time                                    -0.0002      0.001     -0.156      0.877      -0.002       0.002\n",
              "Gender_replaced                                    0.1820      0.197      0.923      0.359      -0.210       0.573\n",
              "==============================================================================\n",
              "Omnibus:                       10.701   Durbin-Watson:                   1.938\n",
              "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               10.926\n",
              "Skew:                           0.681   Prob(JB):                      0.00424\n",
              "Kurtosis:                       3.365   Cond. No.                     1.17e+16\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The smallest eigenvalue is 2.51e-22. This might indicate that there are\n",
              "strong multicollinearity problems or that the design matrix is singular.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnafz68xlG34"
      },
      "source": [
        "**多重共線性の確認：**\n",
        "---\n",
        "Cond. No.\t1.17e+16が非常に大きいため、多重共線性があるため、多重共線性をさらに確認する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvxymPicjY3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c4b6811-69ee-4828-9179-2278ce210b09"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
        "\n",
        "num_cols = model.exog.shape[1] # 説明変数の列数\n",
        "vifs = [vif(model.exog, i) for i in range(0, num_cols)]\n",
        "\n",
        "pd.DataFrame(vifs, index=model.exog_names, columns=['VIF'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/outliers_influence.py:185: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/regression/linear_model.py:1636: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return 1 - self.ssr/self.centered_tss\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VIF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>const</th>\n",
              "      <td>3.481131e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>1.675164e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>2.296600e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>1.478313e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>1.636459e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>2.337493e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Cereals</th>\n",
              "      <td>4.074967e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Root</th>\n",
              "      <td>3.799976e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Suger</th>\n",
              "      <td>9.022607e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Vegetable</th>\n",
              "      <td>5.962198e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Palse</th>\n",
              "      <td>3.305624e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Fruits</th>\n",
              "      <td>5.674020e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cultivation diversity_Spice</th>\n",
              "      <td>4.711458e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Cereals</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Root</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Suger</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Vegetable</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Palse</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Fruits</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wild Diversity_Spice</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Animal Diversity</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>inf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height(cm)</th>\n",
              "      <td>4.956037e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight(kg)</th>\n",
              "      <td>1.681524e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>1.833759e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Waist(cm)</th>\n",
              "      <td>3.745017e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hip(cm)</th>\n",
              "      <td>1.585649e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ratio W/H</th>\n",
              "      <td>1.946005e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <td>2.520075e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <td>2.607116e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <td>3.369160e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>2.887395e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>1.347525e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>3.247359e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>2.786111e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>1.614925e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>1.432214e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>2.436279e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>2.847623e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>1.874280e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>3.346345e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         VIF\n",
              "const                                           3.481131e+04\n",
              "Number of people sharing the same pot           1.675164e+00\n",
              "Age                                             2.296600e+00\n",
              "MIL                                             1.478313e+00\n",
              "Number of cultivation field                     1.636459e+00\n",
              "walking min from your house to Wangige market?  2.337493e+00\n",
              "Cultivation diversity                                    inf\n",
              "Cultivation diversity_Cereals                   4.074967e+01\n",
              "Cultivation diversity_Root                      3.799976e+01\n",
              "Cultivation diversity_Suger                     9.022607e+00\n",
              "Cultivation diversity_Vegetable                 5.962198e+02\n",
              "Cultivation diversity_Palse                     3.305624e+01\n",
              "Cultivation diversity_Fruits                    5.674020e+01\n",
              "Cultivation diversity_Spice                     4.711458e+01\n",
              "Wild Diversity                                           inf\n",
              "Wild Diversity_Cereals                                   NaN\n",
              "Wild Diversity_Root                                      NaN\n",
              "Wild Diversity_Suger                                     inf\n",
              "Wild Diversity_Vegetable                                 inf\n",
              "Wild Diversity_Palse                                     NaN\n",
              "Wild Diversity_Fruits                                    inf\n",
              "Wild Diversity_Spice                                     inf\n",
              "Animal Diversity                                         inf\n",
              "Agrobiodiversity                                         inf\n",
              "Height(cm)                                      4.956037e+01\n",
              "Weight(kg)                                      1.681524e+02\n",
              "BMI                                             1.833759e+02\n",
              "Waist(cm)                                       3.745017e+02\n",
              "Hip(cm)                                         1.585649e+02\n",
              "Ratio W/H                                       1.946005e+02\n",
              "Body Fat (%)                                    2.520075e+00\n",
              "Systolic blood pressure(mmHg)                   2.607116e+00\n",
              "Diastolic blood pressure(mmHg)                  3.369160e+00\n",
              "Grasping power(kg)                              2.887395e+00\n",
              "Total_happness                                  1.347525e+00\n",
              "Activity_level_2                                3.247359e+00\n",
              "Steps                                           2.786111e+00\n",
              "percentage_production                           1.614925e+00\n",
              "Sleeping_time                                   1.432214e+00\n",
              "Economics_time                                  2.436279e+00\n",
              "Crop_time                                       2.847623e+00\n",
              "Livestock_time                                  1.874280e+00\n",
              "Gender_replaced                                 3.346345e+00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TmB7z0Ym_Lt"
      },
      "source": [
        "データセットの再検討：\n",
        "下記のように１０以上の値をとっているものを再検討を行う\n",
        "- Wild Diversity\tinf\n",
        "- Wild Diversity_Cereals\tNaN\n",
        "- Wild Diversity_Root\tNaN\n",
        "- Wild Diversity_Suger\tinf\n",
        "- Wild Diversity_Vegetable\tinf\n",
        "- Wild Diversity_Palse\tNaN\n",
        "- Wild Diversity_Fruits\tinf\n",
        "- Wild Diversity_Spice\tinf\n",
        "- Animal Diversity\tinf\n",
        "- Agrobiodiversity\tinf\n",
        "- Cultivation diversity\tinf\n",
        "\n",
        "説明変数をWild Diversity, Animal, CultivationをAgrobiodiversityに統合\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d0n8OWyl_-o"
      },
      "source": [
        "x_removed = df[[\n",
        "'Number of people sharing the same pot',\n",
        "'Age',\n",
        "'MIL',\n",
        "'Number of cultivation field',\n",
        "'walking min from your house to Wangige market?',\n",
        "'Agrobiodiversity',\n",
        "'Height(cm)',\n",
        "'Weight(kg)',\n",
        "'BMI',\n",
        "'Waist(cm)',\n",
        "'Hip(cm)',\n",
        "'Ratio W/H',\n",
        "'Body Fat (%)',\n",
        "'Systolic blood pressure(mmHg)',\n",
        "'Diastolic blood pressure(mmHg)',\n",
        "'Grasping power(kg)',\n",
        "'Total_happness',\n",
        "'Activity_level_2',\n",
        "'Steps',\n",
        "'percentage_production',\n",
        "'Sleeping_time',\n",
        "'Economics_time',\n",
        "'Crop_time',\n",
        "'Livestock_time',\n",
        "'Gender_replaced']]\n",
        "\n",
        "\n",
        "y = df['BMI_EVENT']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpFAsNAOofBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a2a5d8c-ea39-4cab-d6a0-7f3b35ae1e97"
      },
      "source": [
        "#２回目の検定\n",
        "# 定数項(y切片)を必要とする線形回帰のモデル式ならば必須\n",
        "X = sm.add_constant(x_removed.astype(float))\n",
        "print(X)\n",
        "\n",
        "# 最小二乗法でモデル化\n",
        "model_2nd = sm.OLS(y.astype(float), X)\n",
        "result_2nd = model_2nd.fit()\n",
        "\n",
        "# 重回帰分析の結果を表示\n",
        "result_2nd.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     const  ...  Gender_replaced\n",
            "0      1.0  ...              1.0\n",
            "1      1.0  ...              0.0\n",
            "2      1.0  ...              0.0\n",
            "3      1.0  ...              0.0\n",
            "4      1.0  ...              0.0\n",
            "..     ...  ...              ...\n",
            "127    1.0  ...              0.0\n",
            "128    1.0  ...              1.0\n",
            "129    1.0  ...              1.0\n",
            "130    1.0  ...              1.0\n",
            "131    1.0  ...              0.0\n",
            "\n",
            "[132 rows x 26 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>BMI_EVENT</td>    <th>  R-squared:         </th> <td>   0.658</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.577</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.154</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 05 May 2021</td> <th>  Prob (F-statistic):</th> <td>3.25e-15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>04:21:38</td>     <th>  Log-Likelihood:    </th> <td> -106.67</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   132</td>      <th>  AIC:               </th> <td>   265.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   106</td>      <th>  BIC:               </th> <td>   340.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    25</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "                         <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>                                          <td>    0.4511</td> <td>    9.548</td> <td>    0.047</td> <td> 0.962</td> <td>  -18.479</td> <td>   19.382</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of people sharing the same pot</th>          <td>    0.0114</td> <td>    0.045</td> <td>    0.256</td> <td> 0.798</td> <td>   -0.077</td> <td>    0.100</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Age</th>                                            <td>   -0.0058</td> <td>    0.007</td> <td>   -0.823</td> <td> 0.412</td> <td>   -0.020</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MIL</th>                                            <td>    0.0019</td> <td>    0.029</td> <td>    0.066</td> <td> 0.947</td> <td>   -0.056</td> <td>    0.060</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of cultivation field</th>                    <td>    0.0913</td> <td>    0.102</td> <td>    0.897</td> <td> 0.372</td> <td>   -0.111</td> <td>    0.293</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>walking min from your house to Wangige market?</th> <td>   -0.0002</td> <td>    0.006</td> <td>   -0.028</td> <td> 0.978</td> <td>   -0.011</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Agrobiodiversity</th>                               <td>   -0.0071</td> <td>    0.014</td> <td>   -0.525</td> <td> 0.601</td> <td>   -0.034</td> <td>    0.020</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Height(cm)</th>                                     <td>   -0.0442</td> <td>    0.041</td> <td>   -1.080</td> <td> 0.283</td> <td>   -0.125</td> <td>    0.037</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Weight(kg)</th>                                     <td>    0.0492</td> <td>    0.048</td> <td>    1.029</td> <td> 0.306</td> <td>   -0.046</td> <td>    0.144</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>BMI</th>                                            <td>   -0.0015</td> <td>    0.129</td> <td>   -0.011</td> <td> 0.991</td> <td>   -0.257</td> <td>    0.254</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Waist(cm)</th>                                      <td>   -0.0650</td> <td>    0.063</td> <td>   -1.039</td> <td> 0.301</td> <td>   -0.189</td> <td>    0.059</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Hip(cm)</th>                                        <td>    0.0605</td> <td>    0.056</td> <td>    1.089</td> <td> 0.279</td> <td>   -0.050</td> <td>    0.171</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Ratio W/H</th>                                      <td>    6.6223</td> <td>    6.417</td> <td>    1.032</td> <td> 0.304</td> <td>   -6.099</td> <td>   19.344</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Body Fat (%)</th>                                   <td>    0.0024</td> <td>    0.008</td> <td>    0.302</td> <td> 0.763</td> <td>   -0.014</td> <td>    0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Systolic blood pressure(mmHg)</th>                  <td>    0.0027</td> <td>    0.005</td> <td>    0.582</td> <td> 0.562</td> <td>   -0.007</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Diastolic blood pressure(mmHg)</th>                 <td>    0.0010</td> <td>    0.007</td> <td>    0.139</td> <td> 0.890</td> <td>   -0.014</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Grasping power(kg)</th>                             <td>    0.0067</td> <td>    0.008</td> <td>    0.819</td> <td> 0.415</td> <td>   -0.010</td> <td>    0.023</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total_happness</th>                                 <td>   -0.0234</td> <td>    0.019</td> <td>   -1.251</td> <td> 0.214</td> <td>   -0.061</td> <td>    0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Activity_level_2</th>                               <td>    0.0009</td> <td>    0.001</td> <td>    0.818</td> <td> 0.415</td> <td>   -0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Steps</th>                                          <td>-9.461e-06</td> <td> 1.02e-05</td> <td>   -0.932</td> <td> 0.354</td> <td>-2.96e-05</td> <td> 1.07e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>percentage_production</th>                          <td>   -0.0020</td> <td>    0.004</td> <td>   -0.482</td> <td> 0.630</td> <td>   -0.010</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sleeping_time</th>                                  <td>-9.894e-05</td> <td>    0.001</td> <td>   -0.144</td> <td> 0.885</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Economics_time</th>                                 <td>    0.0010</td> <td>    0.000</td> <td>    2.172</td> <td> 0.032</td> <td> 8.96e-05</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Crop_time</th>                                      <td>   -0.0008</td> <td>    0.000</td> <td>   -1.644</td> <td> 0.103</td> <td>   -0.002</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Livestock_time</th>                                 <td>   -0.0003</td> <td>    0.001</td> <td>   -0.268</td> <td> 0.789</td> <td>   -0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Gender_replaced</th>                                <td>    0.1249</td> <td>    0.180</td> <td>    0.695</td> <td> 0.488</td> <td>   -0.231</td> <td>    0.481</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>21.890</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  27.249</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.979</td> <th>  Prob(JB):          </th> <td>1.21e-06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 4.059</td> <th>  Cond. No.          </th> <td>3.28e+06</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.28e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              BMI_EVENT   R-squared:                       0.658\n",
              "Model:                            OLS   Adj. R-squared:                  0.577\n",
              "Method:                 Least Squares   F-statistic:                     8.154\n",
              "Date:                Wed, 05 May 2021   Prob (F-statistic):           3.25e-15\n",
              "Time:                        04:21:38   Log-Likelihood:                -106.67\n",
              "No. Observations:                 132   AIC:                             265.3\n",
              "Df Residuals:                     106   BIC:                             340.3\n",
              "Df Model:                          25                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==================================================================================================================\n",
              "                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------------------------------------------\n",
              "const                                              0.4511      9.548      0.047      0.962     -18.479      19.382\n",
              "Number of people sharing the same pot              0.0114      0.045      0.256      0.798      -0.077       0.100\n",
              "Age                                               -0.0058      0.007     -0.823      0.412      -0.020       0.008\n",
              "MIL                                                0.0019      0.029      0.066      0.947      -0.056       0.060\n",
              "Number of cultivation field                        0.0913      0.102      0.897      0.372      -0.111       0.293\n",
              "walking min from your house to Wangige market?    -0.0002      0.006     -0.028      0.978      -0.011       0.011\n",
              "Agrobiodiversity                                  -0.0071      0.014     -0.525      0.601      -0.034       0.020\n",
              "Height(cm)                                        -0.0442      0.041     -1.080      0.283      -0.125       0.037\n",
              "Weight(kg)                                         0.0492      0.048      1.029      0.306      -0.046       0.144\n",
              "BMI                                               -0.0015      0.129     -0.011      0.991      -0.257       0.254\n",
              "Waist(cm)                                         -0.0650      0.063     -1.039      0.301      -0.189       0.059\n",
              "Hip(cm)                                            0.0605      0.056      1.089      0.279      -0.050       0.171\n",
              "Ratio W/H                                          6.6223      6.417      1.032      0.304      -6.099      19.344\n",
              "Body Fat (%)                                       0.0024      0.008      0.302      0.763      -0.014       0.019\n",
              "Systolic blood pressure(mmHg)                      0.0027      0.005      0.582      0.562      -0.007       0.012\n",
              "Diastolic blood pressure(mmHg)                     0.0010      0.007      0.139      0.890      -0.014       0.016\n",
              "Grasping power(kg)                                 0.0067      0.008      0.819      0.415      -0.010       0.023\n",
              "Total_happness                                    -0.0234      0.019     -1.251      0.214      -0.061       0.014\n",
              "Activity_level_2                                   0.0009      0.001      0.818      0.415      -0.001       0.003\n",
              "Steps                                          -9.461e-06   1.02e-05     -0.932      0.354   -2.96e-05    1.07e-05\n",
              "percentage_production                             -0.0020      0.004     -0.482      0.630      -0.010       0.006\n",
              "Sleeping_time                                  -9.894e-05      0.001     -0.144      0.885      -0.001       0.001\n",
              "Economics_time                                     0.0010      0.000      2.172      0.032    8.96e-05       0.002\n",
              "Crop_time                                         -0.0008      0.000     -1.644      0.103      -0.002       0.000\n",
              "Livestock_time                                    -0.0003      0.001     -0.268      0.789      -0.002       0.002\n",
              "Gender_replaced                                    0.1249      0.180      0.695      0.488      -0.231       0.481\n",
              "==============================================================================\n",
              "Omnibus:                       21.890   Durbin-Watson:                   2.007\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.249\n",
              "Skew:                           0.979   Prob(JB):                     1.21e-06\n",
              "Kurtosis:                       4.059   Cond. No.                     3.28e+06\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.28e+06. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "690IHJ16os--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "bfecda53-b145-4441-8c79-cd54e0662dc7"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
        "\n",
        "num_cols_2nd = model_2nd.exog.shape[1] # 説明変数の列数\n",
        "vifs = [vif(model_2nd.exog, i) for i in range(0, num_cols_2nd)]\n",
        "\n",
        "pd.DataFrame(vifs, index=model_2nd.exog_names, columns=['VIF'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VIF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>const</th>\n",
              "      <td>32786.587603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>1.386860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>1.668290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>1.190995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>1.321549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>1.283180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>1.258090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Height(cm)</th>\n",
              "      <td>45.530315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight(kg)</th>\n",
              "      <td>156.046045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>169.437731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Waist(cm)</th>\n",
              "      <td>341.984847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hip(cm)</th>\n",
              "      <td>144.916837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ratio W/H</th>\n",
              "      <td>177.860851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Body Fat (%)</th>\n",
              "      <td>2.202328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Systolic blood pressure(mmHg)</th>\n",
              "      <td>2.382479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Diastolic blood pressure(mmHg)</th>\n",
              "      <td>2.761494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>2.449838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>1.260358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>2.736562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>2.526943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>1.279874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>1.270390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>2.063991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>2.435373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>1.716771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>2.891690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         VIF\n",
              "const                                           32786.587603\n",
              "Number of people sharing the same pot               1.386860\n",
              "Age                                                 1.668290\n",
              "MIL                                                 1.190995\n",
              "Number of cultivation field                         1.321549\n",
              "walking min from your house to Wangige market?      1.283180\n",
              "Agrobiodiversity                                    1.258090\n",
              "Height(cm)                                         45.530315\n",
              "Weight(kg)                                        156.046045\n",
              "BMI                                               169.437731\n",
              "Waist(cm)                                         341.984847\n",
              "Hip(cm)                                           144.916837\n",
              "Ratio W/H                                         177.860851\n",
              "Body Fat (%)                                        2.202328\n",
              "Systolic blood pressure(mmHg)                       2.382479\n",
              "Diastolic blood pressure(mmHg)                      2.761494\n",
              "Grasping power(kg)                                  2.449838\n",
              "Total_happness                                      1.260358\n",
              "Activity_level_2                                    2.736562\n",
              "Steps                                               2.526943\n",
              "percentage_production                               1.279874\n",
              "Sleeping_time                                       1.270390\n",
              "Economics_time                                      2.063991\n",
              "Crop_time                                           2.435373\n",
              "Livestock_time                                      1.716771\n",
              "Gender_replaced                                     2.891690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWIj7ODHpNRf"
      },
      "source": [
        "データセットの再検討： 下記のように１０以上の値をとっているものを再検討を行う\n",
        "\n",
        "- Height(cm)\t45.530315\n",
        "- Weight(kg)\t156.046045\n",
        "- BMI\t169.437731\n",
        "- Waist(cm)\t341.984847\n",
        "- Hip(cm)\t144.916837\n",
        "- Ratio W/H\t177.860851\n",
        "\n",
        "上記もVIFが高かっため、説明変数から削除する。\n",
        "また、身体的特徴に関する項目も削除した。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfYsbaZXpEJS"
      },
      "source": [
        "x_feature = df[[\n",
        "'Number of people sharing the same pot',\n",
        "'Age',\n",
        "'MIL',\n",
        "'Number of cultivation field',\n",
        "'walking min from your house to Wangige market?',\n",
        "'Agrobiodiversity',\n",
        "'Grasping power(kg)',\n",
        "'Total_happness',\n",
        "'Activity_level_2',\n",
        "'Steps',\n",
        "'percentage_production',\n",
        "'Sleeping_time',\n",
        "'Economics_time',\n",
        "'Crop_time',\n",
        "'Livestock_time',\n",
        "'Gender_replaced']]\n",
        "\n",
        "\n",
        "y_objective = df['BMI_EVENT']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXIduwKCp2H0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3789aa90-4098-4a3f-a957-e9b6a6bfe2c6"
      },
      "source": [
        "#３回目の検定\n",
        "# 定数項(y切片)を必要とする線形回帰のモデル式ならば必須\n",
        "X = sm.add_constant(x_feature.astype(float))\n",
        "print(X)\n",
        "\n",
        "# 最小二乗法でモデル化\n",
        "model_3rd = sm.OLS(y_objective.astype(float), X)\n",
        "result_3rd = model_3rd.fit()\n",
        "\n",
        "# 重回帰分析の結果を表示\n",
        "result_3rd.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     const  ...  Gender_replaced\n",
            "0      1.0  ...              1.0\n",
            "1      1.0  ...              0.0\n",
            "2      1.0  ...              0.0\n",
            "3      1.0  ...              0.0\n",
            "4      1.0  ...              0.0\n",
            "..     ...  ...              ...\n",
            "127    1.0  ...              0.0\n",
            "128    1.0  ...              1.0\n",
            "129    1.0  ...              1.0\n",
            "130    1.0  ...              1.0\n",
            "131    1.0  ...              0.0\n",
            "\n",
            "[132 rows x 17 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>BMI_EVENT</td>    <th>  R-squared:         </th> <td>   0.092</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.034</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.7326</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 05 May 2021</td> <th>  Prob (F-statistic):</th>  <td> 0.756</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>04:21:38</td>     <th>  Log-Likelihood:    </th> <td> -171.06</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   132</td>      <th>  AIC:               </th> <td>   376.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   115</td>      <th>  BIC:               </th> <td>   425.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "                         <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>                                          <td>    2.1233</td> <td>    1.189</td> <td>    1.785</td> <td> 0.077</td> <td>   -0.232</td> <td>    4.479</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of people sharing the same pot</th>          <td>    0.0447</td> <td>    0.063</td> <td>    0.707</td> <td> 0.481</td> <td>   -0.080</td> <td>    0.170</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Age</th>                                            <td>    0.0010</td> <td>    0.010</td> <td>    0.104</td> <td> 0.918</td> <td>   -0.018</td> <td>    0.020</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>MIL</th>                                            <td>    0.0760</td> <td>    0.043</td> <td>    1.748</td> <td> 0.083</td> <td>   -0.010</td> <td>    0.162</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of cultivation field</th>                    <td>    0.1229</td> <td>    0.151</td> <td>    0.816</td> <td> 0.416</td> <td>   -0.175</td> <td>    0.421</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>walking min from your house to Wangige market?</th> <td>    0.0041</td> <td>    0.008</td> <td>    0.487</td> <td> 0.627</td> <td>   -0.013</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Agrobiodiversity</th>                               <td>   -0.0145</td> <td>    0.020</td> <td>   -0.710</td> <td> 0.479</td> <td>   -0.055</td> <td>    0.026</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Grasping power(kg)</th>                             <td>    0.0124</td> <td>    0.011</td> <td>    1.086</td> <td> 0.280</td> <td>   -0.010</td> <td>    0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total_happness</th>                                 <td>   -0.0216</td> <td>    0.028</td> <td>   -0.772</td> <td> 0.442</td> <td>   -0.077</td> <td>    0.034</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Activity_level_2</th>                               <td>   -0.0015</td> <td>    0.002</td> <td>   -0.916</td> <td> 0.361</td> <td>   -0.005</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Steps</th>                                          <td> 1.616e-05</td> <td> 1.52e-05</td> <td>    1.061</td> <td> 0.291</td> <td> -1.4e-05</td> <td> 4.63e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>percentage_production</th>                          <td>    0.0004</td> <td>    0.006</td> <td>    0.063</td> <td> 0.950</td> <td>   -0.012</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sleeping_time</th>                                  <td>    0.0002</td> <td>    0.001</td> <td>    0.183</td> <td> 0.855</td> <td>   -0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Economics_time</th>                                 <td>    0.0011</td> <td>    0.001</td> <td>    1.574</td> <td> 0.118</td> <td>   -0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Crop_time</th>                                      <td>   -0.0010</td> <td>    0.001</td> <td>   -1.346</td> <td> 0.181</td> <td>   -0.002</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Livestock_time</th>                                 <td>   -0.0006</td> <td>    0.001</td> <td>   -0.448</td> <td> 0.655</td> <td>   -0.003</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Gender_replaced</th>                                <td>   -0.3395</td> <td>    0.241</td> <td>   -1.411</td> <td> 0.161</td> <td>   -0.816</td> <td>    0.137</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 9.956</td> <th>  Durbin-Watson:     </th> <td>   2.146</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>   5.659</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.326</td> <th>  Prob(JB):          </th> <td>  0.0590</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.223</td> <th>  Cond. No.          </th> <td>2.32e+05</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:              BMI_EVENT   R-squared:                       0.092\n",
              "Model:                            OLS   Adj. R-squared:                 -0.034\n",
              "Method:                 Least Squares   F-statistic:                    0.7326\n",
              "Date:                Wed, 05 May 2021   Prob (F-statistic):              0.756\n",
              "Time:                        04:21:38   Log-Likelihood:                -171.06\n",
              "No. Observations:                 132   AIC:                             376.1\n",
              "Df Residuals:                     115   BIC:                             425.1\n",
              "Df Model:                          16                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==================================================================================================================\n",
              "                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------------------------------------------\n",
              "const                                              2.1233      1.189      1.785      0.077      -0.232       4.479\n",
              "Number of people sharing the same pot              0.0447      0.063      0.707      0.481      -0.080       0.170\n",
              "Age                                                0.0010      0.010      0.104      0.918      -0.018       0.020\n",
              "MIL                                                0.0760      0.043      1.748      0.083      -0.010       0.162\n",
              "Number of cultivation field                        0.1229      0.151      0.816      0.416      -0.175       0.421\n",
              "walking min from your house to Wangige market?     0.0041      0.008      0.487      0.627      -0.013       0.021\n",
              "Agrobiodiversity                                  -0.0145      0.020     -0.710      0.479      -0.055       0.026\n",
              "Grasping power(kg)                                 0.0124      0.011      1.086      0.280      -0.010       0.035\n",
              "Total_happness                                    -0.0216      0.028     -0.772      0.442      -0.077       0.034\n",
              "Activity_level_2                                  -0.0015      0.002     -0.916      0.361      -0.005       0.002\n",
              "Steps                                           1.616e-05   1.52e-05      1.061      0.291    -1.4e-05    4.63e-05\n",
              "percentage_production                              0.0004      0.006      0.063      0.950      -0.012       0.012\n",
              "Sleeping_time                                      0.0002      0.001      0.183      0.855      -0.002       0.002\n",
              "Economics_time                                     0.0011      0.001      1.574      0.118      -0.000       0.002\n",
              "Crop_time                                         -0.0010      0.001     -1.346      0.181      -0.002       0.000\n",
              "Livestock_time                                    -0.0006      0.001     -0.448      0.655      -0.003       0.002\n",
              "Gender_replaced                                   -0.3395      0.241     -1.411      0.161      -0.816       0.137\n",
              "==============================================================================\n",
              "Omnibus:                        9.956   Durbin-Watson:                   2.146\n",
              "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                5.659\n",
              "Skew:                          -0.326   Prob(JB):                       0.0590\n",
              "Kurtosis:                       2.223   Cond. No.                     2.32e+05\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.32e+05. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a316SpYuqEAk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "3550ac6b-c86a-466e-c5b5-0db30bee111b"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
        "\n",
        "num_cols_3rd = model_3rd.exog.shape[1] # 説明変数の列数\n",
        "vifs = [vif(model_3rd.exog, i) for i in range(0, num_cols_3rd)]\n",
        "\n",
        "pd.DataFrame(vifs, index=model_3rd.exog_names, columns=['VIF'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VIF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>const</th>\n",
              "      <td>208.022104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>1.132704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>1.274538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>1.075464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>1.181842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>1.167275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>1.170278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>1.960943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>1.148506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>2.579548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>2.324161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>1.083411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>1.194405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>1.773320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>2.049048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>1.594698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>2.123173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       VIF\n",
              "const                                           208.022104\n",
              "Number of people sharing the same pot             1.132704\n",
              "Age                                               1.274538\n",
              "MIL                                               1.075464\n",
              "Number of cultivation field                       1.181842\n",
              "walking min from your house to Wangige market?    1.167275\n",
              "Agrobiodiversity                                  1.170278\n",
              "Grasping power(kg)                                1.960943\n",
              "Total_happness                                    1.148506\n",
              "Activity_level_2                                  2.579548\n",
              "Steps                                             2.324161\n",
              "percentage_production                             1.083411\n",
              "Sleeping_time                                     1.194405\n",
              "Economics_time                                    1.773320\n",
              "Crop_time                                         2.049048\n",
              "Livestock_time                                    1.594698\n",
              "Gender_replaced                                   2.123173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZhXzatOu5aU"
      },
      "source": [
        "機械学習モデルを用いて分析\n",
        "---\n",
        "- LIGHT GBM\n",
        "- ランダムフォレスト\n",
        "- 重回帰分析\n",
        "を用いて分析"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMWAFmxQvkAH"
      },
      "source": [
        "Light GBMにて分析を行う\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHO_h6otu46R"
      },
      "source": [
        "# データ処理ラブラり\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "# データ可視化ライブラリ\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        " \n",
        " \n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        " \n",
        "# Scikit-learn（評価算出）\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHuyPqCbxFvt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_feature, y_objective, test_size=0.2, random_state=None)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZPq5sptz4Hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2235a565-fd1c-4daf-9c71-e8f0d0e98f65"
      },
      "source": [
        "print(X_train)\n",
        "print(y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Number of people sharing the same pot  ...  Gender_replaced\n",
            "41                                       7  ...                1\n",
            "45                                       4  ...                1\n",
            "35                                       3  ...                0\n",
            "44                                       5  ...                1\n",
            "121                                      5  ...                1\n",
            "..                                     ...  ...              ...\n",
            "70                                       4  ...                1\n",
            "99                                       4  ...                0\n",
            "102                                      4  ...                0\n",
            "14                                       4  ...                1\n",
            "26                                       5  ...                1\n",
            "\n",
            "[105 rows x 16 columns]\n",
            "41     4\n",
            "45     2\n",
            "35     1\n",
            "44     4\n",
            "121    4\n",
            "      ..\n",
            "70     2\n",
            "99     3\n",
            "102    4\n",
            "14     2\n",
            "26     4\n",
            "Name: BMI_EVENT, Length: 105, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S79qGJFCtTL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d099357c-f9ad-4c03-ee80-651e38edd8df"
      },
      "source": [
        "lgb.LGBMClassifier(objective='binary')\n",
        "# lgb.LGBMClassifier()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective='binary',\n",
              "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjEpNFzwKco"
      },
      "source": [
        "params = {\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 5,\n",
        "    'verbose': 4,\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0P0oK4Xx8xa"
      },
      "source": [
        "# 訓練・テストデータの設定\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "eval_data = lgb.Dataset(X_test, label=y_test, reference= train_data)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUmd-fqewpdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3647bf-799f-440a-b000-4da316771199"
      },
      "source": [
        "gbm = lgb.train(\n",
        "params,\n",
        "train_data,\n",
        "valid_sets=eval_data,\n",
        "num_boost_round=1000,\n",
        "verbose_eval=4,\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4]\tvalid_0's multi_logloss: 1.16676\n",
            "[8]\tvalid_0's multi_logloss: 1.18872\n",
            "[12]\tvalid_0's multi_logloss: 1.18787\n",
            "[16]\tvalid_0's multi_logloss: 1.20837\n",
            "[20]\tvalid_0's multi_logloss: 1.21693\n",
            "[24]\tvalid_0's multi_logloss: 1.22655\n",
            "[28]\tvalid_0's multi_logloss: 1.24497\n",
            "[32]\tvalid_0's multi_logloss: 1.27149\n",
            "[36]\tvalid_0's multi_logloss: 1.27372\n",
            "[40]\tvalid_0's multi_logloss: 1.28113\n",
            "[44]\tvalid_0's multi_logloss: 1.29777\n",
            "[48]\tvalid_0's multi_logloss: 1.31155\n",
            "[52]\tvalid_0's multi_logloss: 1.33834\n",
            "[56]\tvalid_0's multi_logloss: 1.36\n",
            "[60]\tvalid_0's multi_logloss: 1.37377\n",
            "[64]\tvalid_0's multi_logloss: 1.387\n",
            "[68]\tvalid_0's multi_logloss: 1.40241\n",
            "[72]\tvalid_0's multi_logloss: 1.41178\n",
            "[76]\tvalid_0's multi_logloss: 1.43448\n",
            "[80]\tvalid_0's multi_logloss: 1.44136\n",
            "[84]\tvalid_0's multi_logloss: 1.44657\n",
            "[88]\tvalid_0's multi_logloss: 1.45976\n",
            "[92]\tvalid_0's multi_logloss: 1.48125\n",
            "[96]\tvalid_0's multi_logloss: 1.50633\n",
            "[100]\tvalid_0's multi_logloss: 1.50717\n",
            "[104]\tvalid_0's multi_logloss: 1.50541\n",
            "[108]\tvalid_0's multi_logloss: 1.51566\n",
            "[112]\tvalid_0's multi_logloss: 1.53779\n",
            "[116]\tvalid_0's multi_logloss: 1.54627\n",
            "[120]\tvalid_0's multi_logloss: 1.55637\n",
            "[124]\tvalid_0's multi_logloss: 1.57021\n",
            "[128]\tvalid_0's multi_logloss: 1.56906\n",
            "[132]\tvalid_0's multi_logloss: 1.57751\n",
            "[136]\tvalid_0's multi_logloss: 1.58759\n",
            "[140]\tvalid_0's multi_logloss: 1.58142\n",
            "[144]\tvalid_0's multi_logloss: 1.58001\n",
            "[148]\tvalid_0's multi_logloss: 1.59412\n",
            "[152]\tvalid_0's multi_logloss: 1.60224\n",
            "[156]\tvalid_0's multi_logloss: 1.61306\n",
            "[160]\tvalid_0's multi_logloss: 1.62268\n",
            "[164]\tvalid_0's multi_logloss: 1.62332\n",
            "[168]\tvalid_0's multi_logloss: 1.62897\n",
            "[172]\tvalid_0's multi_logloss: 1.64257\n",
            "[176]\tvalid_0's multi_logloss: 1.65319\n",
            "[180]\tvalid_0's multi_logloss: 1.66493\n",
            "[184]\tvalid_0's multi_logloss: 1.67951\n",
            "[188]\tvalid_0's multi_logloss: 1.68971\n",
            "[192]\tvalid_0's multi_logloss: 1.71019\n",
            "[196]\tvalid_0's multi_logloss: 1.72801\n",
            "[200]\tvalid_0's multi_logloss: 1.7431\n",
            "[204]\tvalid_0's multi_logloss: 1.75041\n",
            "[208]\tvalid_0's multi_logloss: 1.75672\n",
            "[212]\tvalid_0's multi_logloss: 1.76727\n",
            "[216]\tvalid_0's multi_logloss: 1.77531\n",
            "[220]\tvalid_0's multi_logloss: 1.78823\n",
            "[224]\tvalid_0's multi_logloss: 1.80189\n",
            "[228]\tvalid_0's multi_logloss: 1.80861\n",
            "[232]\tvalid_0's multi_logloss: 1.82009\n",
            "[236]\tvalid_0's multi_logloss: 1.83783\n",
            "[240]\tvalid_0's multi_logloss: 1.85339\n",
            "[244]\tvalid_0's multi_logloss: 1.85685\n",
            "[248]\tvalid_0's multi_logloss: 1.87304\n",
            "[252]\tvalid_0's multi_logloss: 1.889\n",
            "[256]\tvalid_0's multi_logloss: 1.89838\n",
            "[260]\tvalid_0's multi_logloss: 1.90661\n",
            "[264]\tvalid_0's multi_logloss: 1.91993\n",
            "[268]\tvalid_0's multi_logloss: 1.91804\n",
            "[272]\tvalid_0's multi_logloss: 1.92103\n",
            "[276]\tvalid_0's multi_logloss: 1.93317\n",
            "[280]\tvalid_0's multi_logloss: 1.94096\n",
            "[284]\tvalid_0's multi_logloss: 1.95944\n",
            "[288]\tvalid_0's multi_logloss: 1.96756\n",
            "[292]\tvalid_0's multi_logloss: 1.98192\n",
            "[296]\tvalid_0's multi_logloss: 1.99687\n",
            "[300]\tvalid_0's multi_logloss: 2.00876\n",
            "[304]\tvalid_0's multi_logloss: 2.02662\n",
            "[308]\tvalid_0's multi_logloss: 2.04213\n",
            "[312]\tvalid_0's multi_logloss: 2.05076\n",
            "[316]\tvalid_0's multi_logloss: 2.05745\n",
            "[320]\tvalid_0's multi_logloss: 2.0674\n",
            "[324]\tvalid_0's multi_logloss: 2.08171\n",
            "[328]\tvalid_0's multi_logloss: 2.10115\n",
            "[332]\tvalid_0's multi_logloss: 2.1018\n",
            "[336]\tvalid_0's multi_logloss: 2.11082\n",
            "[340]\tvalid_0's multi_logloss: 2.12134\n",
            "[344]\tvalid_0's multi_logloss: 2.13292\n",
            "[348]\tvalid_0's multi_logloss: 2.14544\n",
            "[352]\tvalid_0's multi_logloss: 2.16169\n",
            "[356]\tvalid_0's multi_logloss: 2.18159\n",
            "[360]\tvalid_0's multi_logloss: 2.18158\n",
            "[364]\tvalid_0's multi_logloss: 2.19133\n",
            "[368]\tvalid_0's multi_logloss: 2.19485\n",
            "[372]\tvalid_0's multi_logloss: 2.19511\n",
            "[376]\tvalid_0's multi_logloss: 2.20311\n",
            "[380]\tvalid_0's multi_logloss: 2.20912\n",
            "[384]\tvalid_0's multi_logloss: 2.21356\n",
            "[388]\tvalid_0's multi_logloss: 2.22881\n",
            "[392]\tvalid_0's multi_logloss: 2.24004\n",
            "[396]\tvalid_0's multi_logloss: 2.2572\n",
            "[400]\tvalid_0's multi_logloss: 2.27292\n",
            "[404]\tvalid_0's multi_logloss: 2.28731\n",
            "[408]\tvalid_0's multi_logloss: 2.29798\n",
            "[412]\tvalid_0's multi_logloss: 2.31057\n",
            "[416]\tvalid_0's multi_logloss: 2.32403\n",
            "[420]\tvalid_0's multi_logloss: 2.3329\n",
            "[424]\tvalid_0's multi_logloss: 2.33041\n",
            "[428]\tvalid_0's multi_logloss: 2.33456\n",
            "[432]\tvalid_0's multi_logloss: 2.34561\n",
            "[436]\tvalid_0's multi_logloss: 2.36017\n",
            "[440]\tvalid_0's multi_logloss: 2.38053\n",
            "[444]\tvalid_0's multi_logloss: 2.38132\n",
            "[448]\tvalid_0's multi_logloss: 2.38719\n",
            "[452]\tvalid_0's multi_logloss: 2.38459\n",
            "[456]\tvalid_0's multi_logloss: 2.39411\n",
            "[460]\tvalid_0's multi_logloss: 2.39309\n",
            "[464]\tvalid_0's multi_logloss: 2.40768\n",
            "[468]\tvalid_0's multi_logloss: 2.42038\n",
            "[472]\tvalid_0's multi_logloss: 2.43372\n",
            "[476]\tvalid_0's multi_logloss: 2.43901\n",
            "[480]\tvalid_0's multi_logloss: 2.44589\n",
            "[484]\tvalid_0's multi_logloss: 2.45727\n",
            "[488]\tvalid_0's multi_logloss: 2.46374\n",
            "[492]\tvalid_0's multi_logloss: 2.48005\n",
            "[496]\tvalid_0's multi_logloss: 2.48371\n",
            "[500]\tvalid_0's multi_logloss: 2.50308\n",
            "[504]\tvalid_0's multi_logloss: 2.50885\n",
            "[508]\tvalid_0's multi_logloss: 2.52603\n",
            "[512]\tvalid_0's multi_logloss: 2.54525\n",
            "[516]\tvalid_0's multi_logloss: 2.56179\n",
            "[520]\tvalid_0's multi_logloss: 2.58385\n",
            "[524]\tvalid_0's multi_logloss: 2.59123\n",
            "[528]\tvalid_0's multi_logloss: 2.59629\n",
            "[532]\tvalid_0's multi_logloss: 2.60708\n",
            "[536]\tvalid_0's multi_logloss: 2.62427\n",
            "[540]\tvalid_0's multi_logloss: 2.63246\n",
            "[544]\tvalid_0's multi_logloss: 2.65696\n",
            "[548]\tvalid_0's multi_logloss: 2.66976\n",
            "[552]\tvalid_0's multi_logloss: 2.68023\n",
            "[556]\tvalid_0's multi_logloss: 2.69355\n",
            "[560]\tvalid_0's multi_logloss: 2.71223\n",
            "[564]\tvalid_0's multi_logloss: 2.72499\n",
            "[568]\tvalid_0's multi_logloss: 2.73544\n",
            "[572]\tvalid_0's multi_logloss: 2.73467\n",
            "[576]\tvalid_0's multi_logloss: 2.74653\n",
            "[580]\tvalid_0's multi_logloss: 2.75644\n",
            "[584]\tvalid_0's multi_logloss: 2.772\n",
            "[588]\tvalid_0's multi_logloss: 2.78611\n",
            "[592]\tvalid_0's multi_logloss: 2.80046\n",
            "[596]\tvalid_0's multi_logloss: 2.8119\n",
            "[600]\tvalid_0's multi_logloss: 2.82889\n",
            "[604]\tvalid_0's multi_logloss: 2.83619\n",
            "[608]\tvalid_0's multi_logloss: 2.8496\n",
            "[612]\tvalid_0's multi_logloss: 2.86274\n",
            "[616]\tvalid_0's multi_logloss: 2.86584\n",
            "[620]\tvalid_0's multi_logloss: 2.87064\n",
            "[624]\tvalid_0's multi_logloss: 2.88661\n",
            "[628]\tvalid_0's multi_logloss: 2.89119\n",
            "[632]\tvalid_0's multi_logloss: 2.90606\n",
            "[636]\tvalid_0's multi_logloss: 2.92203\n",
            "[640]\tvalid_0's multi_logloss: 2.93695\n",
            "[644]\tvalid_0's multi_logloss: 2.94154\n",
            "[648]\tvalid_0's multi_logloss: 2.96347\n",
            "[652]\tvalid_0's multi_logloss: 2.96744\n",
            "[656]\tvalid_0's multi_logloss: 2.97643\n",
            "[660]\tvalid_0's multi_logloss: 2.98975\n",
            "[664]\tvalid_0's multi_logloss: 3.003\n",
            "[668]\tvalid_0's multi_logloss: 3.0142\n",
            "[672]\tvalid_0's multi_logloss: 3.02923\n",
            "[676]\tvalid_0's multi_logloss: 3.03951\n",
            "[680]\tvalid_0's multi_logloss: 3.04342\n",
            "[684]\tvalid_0's multi_logloss: 3.05581\n",
            "[688]\tvalid_0's multi_logloss: 3.06441\n",
            "[692]\tvalid_0's multi_logloss: 3.08021\n",
            "[696]\tvalid_0's multi_logloss: 3.09159\n",
            "[700]\tvalid_0's multi_logloss: 3.0948\n",
            "[704]\tvalid_0's multi_logloss: 3.10643\n",
            "[708]\tvalid_0's multi_logloss: 3.11924\n",
            "[712]\tvalid_0's multi_logloss: 3.1333\n",
            "[716]\tvalid_0's multi_logloss: 3.15459\n",
            "[720]\tvalid_0's multi_logloss: 3.16806\n",
            "[724]\tvalid_0's multi_logloss: 3.18366\n",
            "[728]\tvalid_0's multi_logloss: 3.19552\n",
            "[732]\tvalid_0's multi_logloss: 3.21338\n",
            "[736]\tvalid_0's multi_logloss: 3.22253\n",
            "[740]\tvalid_0's multi_logloss: 3.24623\n",
            "[744]\tvalid_0's multi_logloss: 3.2582\n",
            "[748]\tvalid_0's multi_logloss: 3.2688\n",
            "[752]\tvalid_0's multi_logloss: 3.27201\n",
            "[756]\tvalid_0's multi_logloss: 3.28985\n",
            "[760]\tvalid_0's multi_logloss: 3.30065\n",
            "[764]\tvalid_0's multi_logloss: 3.31149\n",
            "[768]\tvalid_0's multi_logloss: 3.32403\n",
            "[772]\tvalid_0's multi_logloss: 3.34139\n",
            "[776]\tvalid_0's multi_logloss: 3.34192\n",
            "[780]\tvalid_0's multi_logloss: 3.34372\n",
            "[784]\tvalid_0's multi_logloss: 3.36284\n",
            "[788]\tvalid_0's multi_logloss: 3.38\n",
            "[792]\tvalid_0's multi_logloss: 3.39484\n",
            "[796]\tvalid_0's multi_logloss: 3.40637\n",
            "[800]\tvalid_0's multi_logloss: 3.41623\n",
            "[804]\tvalid_0's multi_logloss: 3.42645\n",
            "[808]\tvalid_0's multi_logloss: 3.4397\n",
            "[812]\tvalid_0's multi_logloss: 3.44779\n",
            "[816]\tvalid_0's multi_logloss: 3.46055\n",
            "[820]\tvalid_0's multi_logloss: 3.47504\n",
            "[824]\tvalid_0's multi_logloss: 3.48784\n",
            "[828]\tvalid_0's multi_logloss: 3.49745\n",
            "[832]\tvalid_0's multi_logloss: 3.50761\n",
            "[836]\tvalid_0's multi_logloss: 3.523\n",
            "[840]\tvalid_0's multi_logloss: 3.52534\n",
            "[844]\tvalid_0's multi_logloss: 3.54764\n",
            "[848]\tvalid_0's multi_logloss: 3.55848\n",
            "[852]\tvalid_0's multi_logloss: 3.56509\n",
            "[856]\tvalid_0's multi_logloss: 3.57365\n",
            "[860]\tvalid_0's multi_logloss: 3.58533\n",
            "[864]\tvalid_0's multi_logloss: 3.59268\n",
            "[868]\tvalid_0's multi_logloss: 3.60606\n",
            "[872]\tvalid_0's multi_logloss: 3.61334\n",
            "[876]\tvalid_0's multi_logloss: 3.62284\n",
            "[880]\tvalid_0's multi_logloss: 3.64303\n",
            "[884]\tvalid_0's multi_logloss: 3.65988\n",
            "[888]\tvalid_0's multi_logloss: 3.6684\n",
            "[892]\tvalid_0's multi_logloss: 3.66942\n",
            "[896]\tvalid_0's multi_logloss: 3.68931\n",
            "[900]\tvalid_0's multi_logloss: 3.7019\n",
            "[904]\tvalid_0's multi_logloss: 3.71926\n",
            "[908]\tvalid_0's multi_logloss: 3.72996\n",
            "[912]\tvalid_0's multi_logloss: 3.74515\n",
            "[916]\tvalid_0's multi_logloss: 3.76095\n",
            "[920]\tvalid_0's multi_logloss: 3.7745\n",
            "[924]\tvalid_0's multi_logloss: 3.78596\n",
            "[928]\tvalid_0's multi_logloss: 3.79692\n",
            "[932]\tvalid_0's multi_logloss: 3.81347\n",
            "[936]\tvalid_0's multi_logloss: 3.81705\n",
            "[940]\tvalid_0's multi_logloss: 3.82609\n",
            "[944]\tvalid_0's multi_logloss: 3.84203\n",
            "[948]\tvalid_0's multi_logloss: 3.84637\n",
            "[952]\tvalid_0's multi_logloss: 3.86248\n",
            "[956]\tvalid_0's multi_logloss: 3.87061\n",
            "[960]\tvalid_0's multi_logloss: 3.87993\n",
            "[964]\tvalid_0's multi_logloss: 3.88757\n",
            "[968]\tvalid_0's multi_logloss: 3.8986\n",
            "[972]\tvalid_0's multi_logloss: 3.90575\n",
            "[976]\tvalid_0's multi_logloss: 3.91641\n",
            "[980]\tvalid_0's multi_logloss: 3.92667\n",
            "[984]\tvalid_0's multi_logloss: 3.93941\n",
            "[988]\tvalid_0's multi_logloss: 3.94083\n",
            "[992]\tvalid_0's multi_logloss: 3.94827\n",
            "[996]\tvalid_0's multi_logloss: 3.9631\n",
            "[1000]\tvalid_0's multi_logloss: 3.96721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MOln0xFzAp3"
      },
      "source": [
        "# y_pred = []\n",
        " \n",
        "# for x in preds:\n",
        "#     y_pred.append(np.argmax(x))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2xF-FZGzEM3"
      },
      "source": [
        "# confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIMTNXG3zMOf"
      },
      "source": [
        "# accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS_iXyWw1dz4"
      },
      "source": [
        "Light GBMのグリッドサーチ\n",
        "---\n",
        "\n",
        "参考：\n",
        "https://ailog.site/2021/03/06/2021/0306/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMTRAqjx2Z_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d264ef0-8052-4b1c-f151-de902f5c586d"
      },
      "source": [
        "gbm = lgb.LGBMClassifier(objective='binary')\n",
        "gbm.get_params()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boosting_type': 'gbdt',\n",
              " 'class_weight': None,\n",
              " 'colsample_bytree': 1.0,\n",
              " 'importance_type': 'split',\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': -1,\n",
              " 'min_child_samples': 20,\n",
              " 'min_child_weight': 0.001,\n",
              " 'min_split_gain': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': -1,\n",
              " 'num_leaves': 31,\n",
              " 'objective': 'binary',\n",
              " 'random_state': None,\n",
              " 'reg_alpha': 0.0,\n",
              " 'reg_lambda': 0.0,\n",
              " 'silent': True,\n",
              " 'subsample': 1.0,\n",
              " 'subsample_for_bin': 200000,\n",
              " 'subsample_freq': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuos0Nf4zRYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ecc1ca-1860-4b14-db05-ceb8e2d51928"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 試行するパラメータを羅列\n",
        "params = {\n",
        "    'num_leaves': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'reg_alpha': [0, 1, 2, 3, 4, 5,10, 100],\n",
        "    'reg_lambda': [10, 15, 18, 20, 21, 22, 23, 25, 27, 29]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(gbm, param_grid=params, cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_score_)\n",
        "print(grid_search.best_params_)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39999999999999997\n",
            "{'num_leaves': 3, 'reg_alpha': 0, 'reg_lambda': 25}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLNZOZ24aixT"
      },
      "source": [
        "y_pred_GBM = grid_search.predict(X_test)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAbtAzKr9jC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd9aed2-648c-4537-ce52-4e8edec8fee7"
      },
      "source": [
        "print(grid_search.best_estimator_.feature_importances_)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0  55  56   0  92 104 123  35  48  35  72   0  61  56  51   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "Tv9E4QWr1DKX",
        "outputId": "2eb0f7b4-09f8-426e-c30d-b8d762b16734"
      },
      "source": [
        "importance = pd.DataFrame(grid_search.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                importance\n",
              "Number of people sharing the same pot                    0\n",
              "Number of cultivation field                              0\n",
              "Sleeping_time                                            0\n",
              "Gender_replaced                                          0\n",
              "Total_happness                                          35\n",
              "Steps                                                   35\n",
              "Activity_level_2                                        48\n",
              "Livestock_time                                          51\n",
              "Age                                                     55\n",
              "MIL                                                     56\n",
              "Crop_time                                               56\n",
              "Economics_time                                          61\n",
              "percentage_production                                   72\n",
              "walking min from your house to Wangige market?          92\n",
              "Agrobiodiversity                                       104\n",
              "Grasping power(kg)                                     123"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ooquedk8QaT"
      },
      "source": [
        "params = {\n",
        "    'num_leaves': [3],\n",
        "    'reg_alpha': [3],\n",
        "    'reg_lambda': [22]\n",
        "}\n",
        "\n",
        "gbm = lgb.train(\n",
        "params,\n",
        "train_data,\n",
        "valid_sets=eval_data,\n",
        "num_boost_round=1000,\n",
        "verbose_eval=4,\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y-cPyRC1o4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176b17fc-8fb6-4786-bcca-18921cb10edf"
      },
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "print('== デフォルト・パラメータの場合 ==')\n",
        "gbm = lgb.LGBMClassifier(objective='binary')\n",
        "\n",
        "score = model_selection.cross_val_score(gbm, X_train, y_train, cv=3) # cv=3は3分割の意\n",
        "print('各正解率', score)\n",
        "print('正解率', score.mean())\n",
        "\n",
        "print('\\n== パラメータをチューニングした場合 ==')\n",
        "gbm = lgb.LGBMClassifier(objective='binary', num_leaves=3, reg_alpha=3, reg_lambda=22)\n",
        "score = model_selection.cross_val_score(gbm, X_train, y_train, cv=3) # cv=3は3分割の意\n",
        "print('各正解率', score)\n",
        "print('正解率', score.mean())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== デフォルト・パラメータの場合 ==\n",
            "各正解率 [0.31428571 0.4        0.34285714]\n",
            "正解率 0.3523809523809524\n",
            "\n",
            "== パラメータをチューニングした場合 ==\n",
            "各正解率 [0.34285714 0.37142857 0.42857143]\n",
            "正解率 0.38095238095238093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXfxaj144MTK"
      },
      "source": [
        "Feature Importance:\n",
        "----\n",
        "\n",
        "参考：\n",
        "https://qiita.com/studio_haneya/items/e70e835c26524d506e19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3juYHQ73amj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7133a4c6-f793-4775-e00a-f7c4d304f221"
      },
      "source": [
        "importance = pd.DataFrame(grid_search.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                importance\n",
              "Number of people sharing the same pot                    0\n",
              "Number of cultivation field                              0\n",
              "Sleeping_time                                            0\n",
              "Gender_replaced                                          0\n",
              "Total_happness                                          35\n",
              "Steps                                                   35\n",
              "Activity_level_2                                        48\n",
              "Livestock_time                                          51\n",
              "Age                                                     55\n",
              "MIL                                                     56\n",
              "Crop_time                                               56\n",
              "Economics_time                                          61\n",
              "percentage_production                                   72\n",
              "walking min from your house to Wangige market?          92\n",
              "Agrobiodiversity                                       104\n",
              "Grasping power(kg)                                     123"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDOoyeZ_bHv"
      },
      "source": [
        "SVMを用いて分析\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRg8LQEW6Ly7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb6ab54-4e35-47f7-a004-3cba7d069a68"
      },
      "source": [
        "#SVMによるサーチ\n",
        "from sklearn import svm, metrics\n",
        "\n",
        "params = [\n",
        "    {\"C\": [1,10,100,1000], \"kernel\":[\"linear\"]},\n",
        "    {\"C\": [1,10,100,1000], \"kernel\":[\"rbf\"], \"gamma\":[0.001, 0.0001]}\n",
        "]\n",
        "\n",
        "# グリッドサーチを行う\n",
        "clf = GridSearchCV( svm.SVC(), params, n_jobs=-1,cv=3,iid=True )\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"学習モデル=\", clf.best_estimator_)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "学習モデル= SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yEGc-b0Tubc",
        "outputId": "0124f4de-9947-44b2-e980-2c747a63ea25"
      },
      "source": [
        "type(y_test)\n",
        "print(y_test)\n",
        "print(y_test.shape)\n",
        "y_test = np.array(y_test)\n",
        "y_test = y_test.reshape(-1,1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111    4\n",
            "86     4\n",
            "81     4\n",
            "1      2\n",
            "120    4\n",
            "0      3\n",
            "71     3\n",
            "40     2\n",
            "3      4\n",
            "6      4\n",
            "27     3\n",
            "128    3\n",
            "22     2\n",
            "125    4\n",
            "115    3\n",
            "52     4\n",
            "10     2\n",
            "126    2\n",
            "130    2\n",
            "105    3\n",
            "77     3\n",
            "23     2\n",
            "89     4\n",
            "11     2\n",
            "18     2\n",
            "4      2\n",
            "91     3\n",
            "Name: BMI_EVENT, dtype: int64\n",
            "(27,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbwDHR1TQzgy",
        "outputId": "a9a949bc-a04d-4070-ad7e-e2d4884c2947"
      },
      "source": [
        "# 検証用データで精度を確認\n",
        "pre = clf.predict(X_test)\n",
        "ac_score = metrics.accuracy_score(pre, y_test)\n",
        "print(\"正解率=\",ac_score)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "正解率= 0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xivxTDE4BbjS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "46a5ebce-3e55-48cf-b714-d8a264d5e887"
      },
      "source": [
        "importance = pd.DataFrame(clf.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-8df7372007c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_importances_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR8qa-C5G6NF"
      },
      "source": [
        "ニューラルネットワークによる分析：\n",
        "---\n",
        "\n",
        "参考URL:\n",
        "https://teratail.com/questions/234326"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZU_WJTQA7lh"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpz_W99qHZee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b34da59-d9db-4dfb-de96-7bdd87cfd383"
      },
      "source": [
        "param_grid = {'hidden_layer_sizes': [(100,100),(10,10),(100,),(10,)],\n",
        "              'max_iter': [10000,1000,100,10]}\n",
        "\n",
        "grid_search_NN = GridSearchCV(MLPClassifier(), param_grid, cv=3)\n",
        "grid_search_NN.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search_NN.best_estimator_)\n",
        "print(grid_search_NN.best_params_)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n",
            "{'hidden_layer_sizes': (100, 100), 'max_iter': 10000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkP0C6TAVoG5",
        "outputId": "4bba37c0-fcfd-4122-abcf-ba957d6434bb"
      },
      "source": [
        "# 検証用データで精度を確認\n",
        "pre_NN = grid_search_NN.predict(X_test)\n",
        "ac_score = metrics.accuracy_score(pre_NN, y_test)\n",
        "print(\"正解率=\",ac_score)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "正解率= 0.4444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "U7HnXQu1I_Zi",
        "outputId": "4d99ee25-4f41-4981-a4d7-e09767337e8c"
      },
      "source": [
        "importance = pd.DataFrame(grid_search_NN.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-987691da07e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jd9nyD5D-On"
      },
      "source": [
        "重回帰分析のグリッドサーチ：\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8P1DlV2Hucq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427164af-eb05-4f7c-e3b2-5d540a1cc8e4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# グリッドサーチを行うためのパラメーター（LogisticRegressionのパラメーター）\n",
        "parameters = [\n",
        "    {'solver': ['liblinear', 'saga'], 'penalty':['l1', 'l2'], 'C': [0.1, 1, 10, 100]},\n",
        "    {'solver': ['newton-cg', 'sag', 'lbfgs' ], 'penalty':['l2'], 'C': [0.1, 1, 10, 100]},\n",
        "]\n",
        "\n",
        "#グリッドサーチ実行\n",
        "classifier = GridSearchCV(LogisticRegression(), parameters, cv=3, n_jobs=-1)\n",
        "classifier.fit(X_train, y_train)\n",
        "print(\"Accuracy score (train): \", classifier.score(X_train, y_train))\n",
        "print(\"Accuracy score (test): \", classifier.score(X_test, y_test))\n",
        "print(classifier.best_estimator_) # ベストのパラメーターを持つ分類器\n",
        "\n",
        "print(classifier.best_score_)\n",
        "print(classifier.best_params_)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (train):  0.3904761904761905\n",
            "Accuracy score (test):  0.4074074074074074\n",
            "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.39999999999999997\n",
            "{'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht9BZe-PZP4_",
        "outputId": "eec21708-8c56-4fb5-d9a8-d877db992ae0"
      },
      "source": [
        "# 検証用データで精度を確認\n",
        "pre_lr = classifier.predict(X_test)\n",
        "ac_score_ir = metrics.accuracy_score(pre_lr, y_test)\n",
        "print(\"正解率=\",ac_score_ir)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "正解率= 0.4074074074074074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "JClv0kDeI0ID",
        "outputId": "55e85900-3c5b-437d-c8a8-1d8727887428"
      },
      "source": [
        "importance = pd.DataFrame(classifier.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-fbfb73cb0fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_importances_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKPqo4gfZ2Ti"
      },
      "source": [
        "ランダムフォレストによるグリッドサーチ\n",
        "----\n",
        "参考URL：　https://watlab-blog.com/2020/02/20/grid-search-decisiontree/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0360vV4JbDP",
        "outputId": "2e4af0a1-2a94-4716-9fe4-e293e60589df"
      },
      "source": [
        "from sklearn import tree\n",
        "# グリッドサーチ用のパラメータを辞書型で設定\n",
        "param = {'max_depth':[1, 2, 3, 4, 5],\n",
        "         'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "         'min_samples_split':[2, 3, 4, 5]}\n",
        " \n",
        "# 決定木による学習\n",
        "tree = GridSearchCV(tree.DecisionTreeClassifier(),   # グリッドサーチで決定木を定義\n",
        "                   param, cv=5, iid=True)\n",
        "tree.fit(X_train, y_train)                           # フィッティング\n",
        " \n",
        "# スコアとパラメータの組み合わせ\n",
        "scores = tree.cv_results_['mean_test_score']\n",
        "params = tree.cv_results_['params']\n",
        " \n",
        "# 結果の確認\n",
        "best_tree = tree.best_estimator_\n",
        "print('最良条件:\\n', best_tree)\n",
        "print('訓練スコア:\\n', best_tree.score(X_train, y_train))\n",
        "print('テストスコア:\\n', best_tree.score(X_test, y_test))\n",
        "for i in range(len(scores)):\n",
        "    print(scores[i], params[i])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最良条件:\n",
            " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "訓練スコア:\n",
            " 0.44761904761904764\n",
            "テストスコア:\n",
            " 0.4444444444444444\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 6, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 6, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 4}\n",
            "0.38095238095238093 {'max_depth': 1, 'min_samples_leaf': 7, 'min_samples_split': 5}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 8, 'min_samples_split': 4}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 9, 'min_samples_split': 3}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 9, 'min_samples_split': 4}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 9, 'min_samples_split': 5}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
            "0.3619047619047619 {'max_depth': 1, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 6, 'min_samples_split': 3}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 6, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 7, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 2, 'min_samples_leaf': 7, 'min_samples_split': 5}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 8, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 9, 'min_samples_split': 5}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
            "0.26666666666666666 {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "0.2571428571428571 {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
            "0.23809523809523808 {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
            "0.24761904761904763 {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "0.20952380952380953 {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.20952380952380953 {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "0.20952380952380953 {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "0.20952380952380953 {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 3}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 4}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 4}\n",
            "0.18095238095238095 {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 5}\n",
            "0.2761904761904762 {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "0.2761904761904762 {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
            "0.2761904761904762 {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 5}\n",
            "0.2571428571428571 {'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.2571428571428571 {'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "0.2571428571428571 {'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
            "0.2571428571428571 {'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
            "0.3333333333333333 {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
            "0.3238095238095238 {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
            "0.29523809523809524 {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "0.23809523809523808 {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.23809523809523808 {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "0.23809523809523808 {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "0.23809523809523808 {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 3}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 4}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 4}\n",
            "0.20952380952380953 {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 5}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 4}\n",
            "0.3047619047619048 {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "0.3142857142857143 {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 3}\n",
            "0.3238095238095238 {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 4}\n",
            "0.3238095238095238 {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 4, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 4, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 4, 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 4, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
            "0.26666666666666666 {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
            "0.26666666666666666 {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
            "0.26666666666666666 {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
            "0.3047619047619048 {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
            "0.3238095238095238 {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
            "0.3047619047619048 {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4}\n",
            "0.3142857142857143 {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
            "0.2857142857142857 {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
            "0.22857142857142856 {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "0.22857142857142856 {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 3}\n",
            "0.22857142857142856 {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 4}\n",
            "0.22857142857142856 {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
            "0.17142857142857143 {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 2}\n",
            "0.17142857142857143 {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 3}\n",
            "0.17142857142857143 {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 4}\n",
            "0.17142857142857143 {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
            "0.20952380952380953 {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
            "0.20952380952380953 {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
            "0.20952380952380953 {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 4}\n",
            "0.20952380952380953 {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 5}\n",
            "0.29523809523809524 {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "0.29523809523809524 {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
            "0.29523809523809524 {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 4}\n",
            "0.29523809523809524 {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 5}\n",
            "0.3142857142857143 {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
            "0.3142857142857143 {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 3}\n",
            "0.3047619047619048 {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 4}\n",
            "0.3142857142857143 {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 5}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4}\n",
            "0.2761904761904762 {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69VcCP3xb_9V"
      },
      "source": [
        "y_pred_RR = tree.predict(X_test)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "c5AQ-jL3QCD6",
        "outputId": "ac452875-1586-4213-94f4-d0dafdec5266"
      },
      "source": [
        "print(best_tree.best_score_)\n",
        "print(best_tree.best_params_)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-f15d199f1b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'best_score_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "kOoD4eW1aJJk",
        "outputId": "9dea3af9-fb58-4593-ffba-ab81d54a9003"
      },
      "source": [
        "importance = pd.DataFrame(tree.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                importance\n",
              "Number of people sharing the same pot                  0.0\n",
              "Age                                                    0.0\n",
              "Number of cultivation field                            0.0\n",
              "walking min from your house to Wangige market?         0.0\n",
              "Agrobiodiversity                                       0.0\n",
              "Grasping power(kg)                                     0.0\n",
              "Total_happness                                         0.0\n",
              "Activity_level_2                                       0.0\n",
              "Steps                                                  0.0\n",
              "percentage_production                                  0.0\n",
              "Sleeping_time                                          0.0\n",
              "Economics_time                                         0.0\n",
              "Crop_time                                              0.0\n",
              "Livestock_time                                         0.0\n",
              "Gender_replaced                                        0.0\n",
              "MIL                                                    1.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfd6Vcw_bgFU"
      },
      "source": [
        "XGboostのによるグリッドサーチ：\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMgPt6gOoXXf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrRrpZrabeKc",
        "outputId": "9283710f-71bf-49b6-bb17-1dc67536860a"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "cv_params = {'objective':['multi:softprob'],  \n",
        "             'num_class': [4],\n",
        "             'n_estimators':[500],\n",
        "             'booster': ['gbtree'],\n",
        "             'learning_rate':[0.01, 0.03, 0.1, 0.3, 0.5],\n",
        "             'min_split_loss':[1],\n",
        "             'max_depth':[1, 3, 7, 8, 9, 10],\n",
        "             'min_child_weight':[1, 2, 3, 4, 5],\n",
        "             'subsample':[0.5, 0.75, 1.0],\n",
        "             'colsample_bytree':[0.5, 0.75, 1.0]\n",
        "            }\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) \n",
        "\n",
        "bst_grid = GridSearchCV(xgb.XGBClassifier(),                           # 推定器（Estimator）\n",
        "                        param_grid=cv_params,          # パラメータ\n",
        "                        cv=skf,                        # 交差検証ジェネレーター\n",
        "                        scoring=\"accuracy\",        # 検証用データの予測を評価する指標\n",
        "                        n_jobs=1,                      # 並行して実行するジョブの数\n",
        "                        verbose=10)                     # 学習の経過の表示(非表示)\n",
        "\n",
        "bst_grid = bst_grid.fit(X_train,                       # 使用するデータセット\n",
        "                        y_train,\n",
        "                        early_stopping_rounds=10,      # アーリーストッピング\n",
        "                        eval_set=[(X_test, y_test)],   # 学習に用いる検証用データ\n",
        "                        eval_metric='mlogloss',        # アーリーストッピングに使用する指標\n",
        "                        verbose=100)                     # 学習の経過の表示(非表示)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 1350 candidates, totalling 5400 fits\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38404\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.26074\n",
            "[200]\tvalidation_0-mlogloss:1.20521\n",
            "Stopping. Best iteration:\n",
            "[230]\tvalidation_0-mlogloss:1.19802\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38334\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[100]\tvalidation_0-mlogloss:1.26038\n",
            "[200]\tvalidation_0-mlogloss:1.20394\n",
            "[300]\tvalidation_0-mlogloss:1.17357\n",
            "Stopping. Best iteration:\n",
            "[339]\tvalidation_0-mlogloss:1.16532\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38498\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.29916\n",
            "Stopping. Best iteration:\n",
            "[155]\tvalidation_0-mlogloss:1.27709\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38401\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.2444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[200]\tvalidation_0-mlogloss:1.18219\n",
            "[300]\tvalidation_0-mlogloss:1.14411\n",
            "Stopping. Best iteration:\n",
            "[384]\tvalidation_0-mlogloss:1.12272\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.38422\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.25537\n",
            "[200]\tvalidation_0-mlogloss:1.19513\n",
            "[300]\tvalidation_0-mlogloss:1.16819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping. Best iteration:\n",
            "[339]\tvalidation_0-mlogloss:1.15881\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.38394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.26706\n",
            "[200]\tvalidation_0-mlogloss:1.20803\n",
            "[300]\tvalidation_0-mlogloss:1.17721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping. Best iteration:\n",
            "[332]\tvalidation_0-mlogloss:1.16805\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.38484\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.287\n",
            "Stopping. Best iteration:\n",
            "[186]\tvalidation_0-mlogloss:1.26086\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.38359\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[100]\tvalidation_0-mlogloss:1.23723\n",
            "[200]\tvalidation_0-mlogloss:1.16281\n",
            "[300]\tvalidation_0-mlogloss:1.1288\n",
            "[400]\tvalidation_0-mlogloss:1.10617\n",
            "Stopping. Best iteration:\n",
            "[429]\tvalidation_0-mlogloss:1.09926\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.3s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38438\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.26322\n",
            "[200]\tvalidation_0-mlogloss:1.20235\n",
            "[300]\tvalidation_0-mlogloss:1.16477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[400]\tvalidation_0-mlogloss:1.14421\n",
            "[499]\tvalidation_0-mlogloss:1.13203\n",
            "[CV]  booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.3s\n",
            "[CV] booster=gbtree, colsample_bytree=0.5, learning_rate=0.01, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38514\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[100]\tvalidation_0-mlogloss:1.27238\n",
            "[200]\tvalidation_0-mlogloss:1.21737\n",
            "[300]\tvalidation_0-mlogloss:1.18721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.27565\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30767\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.09214\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[21]\tvalidation_0-mlogloss:1.12695\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.407, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33528\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.16474\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37488\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.21969\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30892\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.04912\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33709\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.22673\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33572\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[17]\tvalidation_0-mlogloss:1.1561\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35432\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[16]\tvalidation_0-mlogloss:1.24723\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37146\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.07579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32235\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[34]\tvalidation_0-mlogloss:1.08477\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34164\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.12855\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.2813\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30685\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[25]\tvalidation_0-mlogloss:1.06093\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[21]\tvalidation_0-mlogloss:1.12819\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33528\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[15]\tvalidation_0-mlogloss:1.16681\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37437\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22235\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30892\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[86]\tvalidation_0-mlogloss:1.05458\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32604\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.22761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.222, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33737\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1572\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35432\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.30712\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36472\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.11212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32235\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[34]\tvalidation_0-mlogloss:1.10746\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34238\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.15827\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33357\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.27891\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30737\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.12237\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[20]\tvalidation_0-mlogloss:1.11328\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34448\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[15]\tvalidation_0-mlogloss:1.17043\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37436\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22201\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30842\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.05129\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32459\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.23655\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33737\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.19631\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35432\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.32935\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1176\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31154\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.19043\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34512\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.15304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33357\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.28896\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30621\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13374\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.20045\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34526\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[76]\tvalidation_0-mlogloss:1.16288\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35261\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.25725\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3091\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[81]\tvalidation_0-mlogloss:1.09869\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.22206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.29911\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15184\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31154\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.20731\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3538\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.16079\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33357\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.306\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12671\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.20894\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34621\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19362\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35261\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[81]\tvalidation_0-mlogloss:1.23483\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[79]\tvalidation_0-mlogloss:1.09712\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31252\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.20813\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.30829\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.23209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37726\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.30205\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36217\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[21]\tvalidation_0-mlogloss:1.00199\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36729\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.13846\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33984\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22521\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33956\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.24554\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31066\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.10846\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35154\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.18349\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34056\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.26023\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37484\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[78]\tvalidation_0-mlogloss:1.25625\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34857\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.10412\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31406\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31986\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19224\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.378\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27117\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37063\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.03534\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35756\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[25]\tvalidation_0-mlogloss:1.12976\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.407, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32776\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.17976\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33813\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29647\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.20963\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33838\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.12342\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3501\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.25128\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36288\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.31883\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33618\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[79]\tvalidation_0-mlogloss:1.05344\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31627\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.23767\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34614\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.21208\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3666\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.3083\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37062\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36105\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.19888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.20291\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.337\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.3129\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34902\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.17862\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33072\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[19]\tvalidation_0-mlogloss:1.17505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36703\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25016\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35655\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[14]\tvalidation_0-mlogloss:1.30927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32551\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.07735\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26261\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25512\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35355\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31829\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34354\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12215\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34566\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.20118\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33001\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.26304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31804\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34423\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34171\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[75]\tvalidation_0-mlogloss:1.24814\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.222, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36833\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[23]\tvalidation_0-mlogloss:1.24355\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37218\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.34007\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.115, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.11091\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.22771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29918\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14437\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.23579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18573\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34102\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19166\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35523\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[86]\tvalidation_0-mlogloss:1.2779\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35444\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-mlogloss:1.23506\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35994\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[73]\tvalidation_0-mlogloss:1.30537\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3231\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.18708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32687\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.20609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3162\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25454\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36918\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35943\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[22]\tvalidation_0-mlogloss:1.09209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.37912\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.20017\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33845\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25625\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34187\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27856\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32482\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-mlogloss:1.12317\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34524\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[78]\tvalidation_0-mlogloss:1.0947\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[79]\tvalidation_0-mlogloss:1.27715\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39276\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[73]\tvalidation_0-mlogloss:1.25704\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.06443\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31406\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31986\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19224\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.378\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27117\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37063\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[19]\tvalidation_0-mlogloss:0.996232\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35339\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.16484\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32764\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22596\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34651\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26834\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25348\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33558\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[84]\tvalidation_0-mlogloss:1.1095\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38091\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[35]\tvalidation_0-mlogloss:1.24734\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28841\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.07405\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31627\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.23767\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34614\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.21208\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3666\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.3083\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37062\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36105\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.1703\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.29387\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.337\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.30255\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34902\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15898\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3244\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.12326\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38825\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27894\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[72]\tvalidation_0-mlogloss:1.30101\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.07649\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26261\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25512\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35355\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31829\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34354\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12215\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34566\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.21209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33001\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.26304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31804\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34423\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34171\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.27307\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.26793\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37218\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.33205\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[83]\tvalidation_0-mlogloss:1.08721\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.22771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29918\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14437\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.23579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18573\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34102\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19166\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35523\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.3052\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35444\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-mlogloss:1.23506\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35994\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.32463\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3231\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.18708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32687\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.20609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3162\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25454\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36918\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35943\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[22]\tvalidation_0-mlogloss:1.09209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.37912\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.20017\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33845\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25625\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34187\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27856\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32482\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-mlogloss:1.12317\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34524\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[78]\tvalidation_0-mlogloss:1.0947\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[75]\tvalidation_0-mlogloss:1.27146\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39276\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[73]\tvalidation_0-mlogloss:1.25704\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.06443\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31406\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31986\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19224\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.378\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27117\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37063\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[19]\tvalidation_0-mlogloss:0.996232\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35339\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.16484\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32764\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22596\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34651\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26834\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25348\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33558\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[84]\tvalidation_0-mlogloss:1.1095\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38091\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[35]\tvalidation_0-mlogloss:1.24734\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28841\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.07405\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31627\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.23767\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34614\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.21208\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3666\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.3083\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37062\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36105\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.1703\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.29387\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.337\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.30255\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34902\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15898\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3244\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.12326\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38825\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27894\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[72]\tvalidation_0-mlogloss:1.30101\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.07649\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26261\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25512\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35355\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31829\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34354\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12215\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34566\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.21209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33001\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.26304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31804\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34423\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34171\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.27307\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.26793\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37218\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.33205\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[83]\tvalidation_0-mlogloss:1.08721\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.22771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29918\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14437\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.23579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18573\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34102\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19166\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35523\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.3052\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35444\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-mlogloss:1.23506\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35994\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.32463\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3231\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.18708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32687\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.20609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3162\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25454\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36918\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35943\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[22]\tvalidation_0-mlogloss:1.09209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.37912\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.20017\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33845\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25625\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34187\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27856\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32482\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-mlogloss:1.12317\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34524\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[78]\tvalidation_0-mlogloss:1.0947\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[76]\tvalidation_0-mlogloss:1.26725\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39276\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[73]\tvalidation_0-mlogloss:1.25704\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.06443\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31406\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31986\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19224\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.378\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27117\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37063\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[19]\tvalidation_0-mlogloss:0.996232\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35339\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.16484\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32764\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22596\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34651\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26834\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25348\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33558\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[84]\tvalidation_0-mlogloss:1.1095\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38091\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[35]\tvalidation_0-mlogloss:1.24734\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28841\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.07405\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31627\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.23767\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34614\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.21208\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3666\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.3083\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37062\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36105\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.1703\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.29387\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.337\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.30255\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34902\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15898\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3244\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.12326\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38825\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27894\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[72]\tvalidation_0-mlogloss:1.30101\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.07649\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26261\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25512\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35355\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31829\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34354\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12215\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34566\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.21209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33001\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.26304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31804\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34423\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34171\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.27307\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.26793\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37218\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.33205\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[83]\tvalidation_0-mlogloss:1.08721\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.22771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29918\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14437\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.23579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18573\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34102\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19166\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35523\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.3052\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35444\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-mlogloss:1.23506\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35994\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.32463\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3231\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.18708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32687\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.20609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3162\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25454\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36918\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35943\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[22]\tvalidation_0-mlogloss:1.09209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.37912\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.20017\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33845\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25625\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34187\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27856\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32482\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[32]\tvalidation_0-mlogloss:1.12317\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34524\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[78]\tvalidation_0-mlogloss:1.0947\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[76]\tvalidation_0-mlogloss:1.26725\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39276\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[73]\tvalidation_0-mlogloss:1.25704\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.06443\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31406\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2212\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31986\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19224\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.378\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27117\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37063\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[19]\tvalidation_0-mlogloss:0.996232\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35339\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.16484\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32764\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.22596\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34651\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26834\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25348\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33558\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[84]\tvalidation_0-mlogloss:1.1095\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38091\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[35]\tvalidation_0-mlogloss:1.24734\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28841\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32841\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[82]\tvalidation_0-mlogloss:1.07405\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31627\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.23767\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34614\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.21208\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3666\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.3083\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37062\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.500, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36105\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.1703\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.29387\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.337\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.30255\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34902\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15898\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3244\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[80]\tvalidation_0-mlogloss:1.12326\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38825\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.27894\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35336\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[72]\tvalidation_0-mlogloss:1.30101\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32479\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[77]\tvalidation_0-mlogloss:1.07649\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26261\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33939\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25512\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35355\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31829\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34354\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12215\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34566\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.21209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33001\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.26304\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31804\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34423\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.22927\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34171\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[85]\tvalidation_0-mlogloss:1.27307\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.26793\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37218\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.33205\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31346\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[83]\tvalidation_0-mlogloss:1.08721\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31145\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.22771\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31615\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.19321\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33811\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29918\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.342\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14437\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.23579\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33874\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18573\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3241\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34102\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19166\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35523\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.3052\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35444\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-mlogloss:1.23506\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35994\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.32463\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3231\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.18708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.3, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.13963\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31408\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.17221\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34164\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.25913\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[20]\tvalidation_0-mlogloss:1.10062\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.28722\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[25]\tvalidation_0-mlogloss:1.07991\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.222, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32206\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.12247\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30949\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.25209\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26385\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.04463\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[21]\tvalidation_0-mlogloss:1.09974\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3083\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14033\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3776\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25306\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.26413\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.04998\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.313\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18877\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31436\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.16897\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34164\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.27368\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.1254\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.28722\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.10287\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32206\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.18423\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30868\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.25352\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26237\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.04981\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.09926\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3083\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.14766\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37672\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25735\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.26413\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.06373\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29564\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21015\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31321\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.16234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34164\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28164\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.35954\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13906\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.28722\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18509\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32322\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18029\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30984\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23617\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26294\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[20]\tvalidation_0-mlogloss:1.09898\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[50]\tvalidation_0-mlogloss:1.10315\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32327\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.15288\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37635\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.25734\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.26326\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.04256\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29247\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.2234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31321\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.174\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.34164\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.30374\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.09202\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26909\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.16791\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32579\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16206\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30984\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.30373\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26097\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1194\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[49]\tvalidation_0-mlogloss:1.20566\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32447\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.16345\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.26851\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.2642\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.11377\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.17172\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26909\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.18465\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33925\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.15714\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30984\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.30984\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.26435\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.11418\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[46]\tvalidation_0-mlogloss:1.19589\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32578\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.18326\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33987\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.26923\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.26498\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[46]\tvalidation_0-mlogloss:1.11191\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=1, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29248\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.17094\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.2764\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23672\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38221\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29158\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36272\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.04639\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.37222\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[12]\tvalidation_0-mlogloss:1.11911\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32057\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28237\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33372\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31589\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.27504\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.06943\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34237\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[44]\tvalidation_0-mlogloss:1.22901\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32745\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.32024\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38734\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.31116\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33555\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.13486\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28636\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.20629\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29088\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.16436\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29706\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37234\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[17]\tvalidation_0-mlogloss:0.973789\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.16207\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30309\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.24777\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32731\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26256\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36344\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.19279\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31849\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.13616\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34041\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23861\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36909\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.30515\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31626\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.13498\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.26505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33075\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22607\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36188\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31068\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37133\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13785\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35836\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[13]\tvalidation_0-mlogloss:1.23519\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31281\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.26129\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.29189\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33527\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15342\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30616\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21903\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3662\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[47]\tvalidation_0-mlogloss:1.2585\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35691\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.30402\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29652\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[46]\tvalidation_0-mlogloss:1.02725\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.25511\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31848\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22132\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3398\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29153\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32245\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.05753\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32644\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21808\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.444, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23267\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32534\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23071\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32331\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[44]\tvalidation_0-mlogloss:1.21793\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.36762\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.25854\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37659\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.36213\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27519\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.09034\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16936\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31273\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19318\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31727\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28056\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31851\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.34164\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34376\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.20756\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35486\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.3434\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29131\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.20634\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=3, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31771\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.20646\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29033\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25559\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31038\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3592\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.08499\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.39374\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.29628\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34078\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26881\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10211\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[53]\tvalidation_0-mlogloss:1.12715\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32926\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.26622\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.41908\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.34507\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[49]\tvalidation_0-mlogloss:1.06665\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28636\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.20629\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29088\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.16436\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29706\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37234\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10312\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34721\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.09174\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.538, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34181\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.24141\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36344\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15302\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.07504\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39637\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.31815\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38325\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.35609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[43]\tvalidation_0-mlogloss:0.990718\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.26505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33075\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22607\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36188\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31068\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37133\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13785\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35836\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.22423\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32452\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28009\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33527\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29587\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18938\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.4046\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.28078\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35467\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.35246\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29567\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.03291\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.25511\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31848\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22132\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3398\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29153\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32245\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.05753\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32644\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21808\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.444, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32534\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23071\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32331\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.25999\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38159\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.26945\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37659\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.3282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27519\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.09034\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16936\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31273\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19318\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31727\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28056\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31851\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34376\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.20756\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35486\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.3434\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29131\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.20634\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=7, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31771\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.20646\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29033\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25559\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31038\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3592\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.08499\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.39374\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.29628\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34078\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26881\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10211\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[53]\tvalidation_0-mlogloss:1.12715\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32405\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.22594\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.41908\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.34507\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[49]\tvalidation_0-mlogloss:1.06665\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28636\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.20629\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29088\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.16436\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29706\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37234\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10312\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34721\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.09174\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.538, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34181\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.24141\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36344\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15302\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.07504\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39637\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.31815\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38325\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.35609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[43]\tvalidation_0-mlogloss:0.990718\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.26505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33075\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22607\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36188\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31068\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37133\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13785\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35836\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.22423\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32452\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28009\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33527\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29587\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18938\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.4046\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.28078\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35467\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.35246\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29567\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.03291\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.25511\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31848\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22132\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3398\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29153\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32245\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.05753\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32644\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21808\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.444, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32534\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23071\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32331\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.25999\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38159\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.26945\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37659\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.3282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27519\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.09034\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16936\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31273\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19318\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31727\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28056\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31851\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34376\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.20756\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35486\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.3434\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29131\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.20634\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=8, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31771\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.20646\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29033\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25559\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31038\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3592\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.08499\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.39374\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.29628\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34078\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26881\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10211\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[53]\tvalidation_0-mlogloss:1.12715\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32405\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.22594\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.41908\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.34507\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[49]\tvalidation_0-mlogloss:1.06665\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28636\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.20629\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29088\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.16436\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29706\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37234\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10312\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34721\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.09174\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.538, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34181\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.24141\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36344\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15302\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.07504\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39637\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.31815\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38325\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.35609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[43]\tvalidation_0-mlogloss:0.990718\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.26505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33075\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22607\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36188\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31068\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37133\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13785\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35836\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.22423\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32452\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28009\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33527\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29587\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18938\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.407, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.4046\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.28078\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35467\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.35246\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29567\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.03291\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.25511\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31848\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22132\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3398\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29153\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32245\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.05753\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32644\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21808\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.444, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32534\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23071\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32331\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.25999\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38159\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.26945\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37659\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.3282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27519\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.09034\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16936\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31273\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19318\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31727\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28056\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31851\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34376\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.20756\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35486\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.3434\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29131\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.20634\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=9, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31771\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.20646\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29033\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.25559\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.31038\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3592\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[18]\tvalidation_0-mlogloss:1.08499\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.39374\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.29628\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.323\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34078\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.26881\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10211\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.33763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[53]\tvalidation_0-mlogloss:1.12715\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32405\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.22594\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.41908\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.34507\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27371\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[49]\tvalidation_0-mlogloss:1.06665\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=1, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.2s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28636\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.20629\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.481, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29088\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-mlogloss:1.16436\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.38256\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.29706\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37234\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.10312\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34721\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.09174\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30323\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.23282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.538, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.34181\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-mlogloss:1.24141\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.36344\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.15302\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.31763\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.07504\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.39637\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.31815\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38325\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.35609\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.30641\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[43]\tvalidation_0-mlogloss:0.990718\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=2, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.28906\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.26505\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.296, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.33075\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22607\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.36188\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.31068\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.154, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.37133\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.13785\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.35836\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.22423\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32452\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28009\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.462, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.32127\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.33527\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.19234\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29587\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.18938\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.407, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.4046\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[51]\tvalidation_0-mlogloss:1.28078\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35467\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.35246\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.192, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29567\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.03291\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=3, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.29394\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-mlogloss:1.25511\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.370, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31848\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.22132\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.3398\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.29153\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.32245\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[7]\tvalidation_0-mlogloss:1.05753\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32644\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.21808\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.444, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.30377\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.1541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.31708\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.231, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.32534\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.23071\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.423, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.32331\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[48]\tvalidation_0-mlogloss:1.25999\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.296, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.38159\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.26945\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.37659\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[41]\tvalidation_0-mlogloss:1.3282\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.154, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.27519\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[45]\tvalidation_0-mlogloss:1.09034\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=4, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27116\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[4]\tvalidation_0-mlogloss:1.17541\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.27751\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.15888\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.346, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31399\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[3]\tvalidation_0-mlogloss:1.28996\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.269, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5 \n",
            "[0]\tvalidation_0-mlogloss:1.31921\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16936\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.5, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31273\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[11]\tvalidation_0-mlogloss:1.19318\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.259, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31727\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.28056\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.2973\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.192, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75 \n",
            "[0]\tvalidation_0-mlogloss:1.31851\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[9]\tvalidation_0-mlogloss:1.16761\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=0.75, score=0.385, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-mlogloss:1.3451\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.333, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.34376\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[42]\tvalidation_0-mlogloss:1.20756\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.269, total=   0.1s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.35486\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[8]\tvalidation_0-mlogloss:1.3434\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.308, total=   0.0s\n",
            "[CV] booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0 \n",
            "[0]\tvalidation_0-mlogloss:1.29131\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-mlogloss:1.20634\n",
            "\n",
            "[CV]  booster=gbtree, colsample_bytree=1.0, learning_rate=0.5, max_depth=10, min_child_weight=5, min_split_loss=1, n_estimators=500, num_class=4, objective=multi:softprob, subsample=1.0, score=0.346, total=   0.0s\n",
            "[0]\tvalidation_0-mlogloss:1.33571\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "Stopping. Best iteration:\n",
            "[10]\tvalidation_0-mlogloss:1.17782\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 5400 out of 5400 | elapsed: 10.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eshGgTo8O41k"
      },
      "source": [
        "Prediction\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym_N2VtWO4Ru"
      },
      "source": [
        "y_pred_xgb = bst_grid.predict(X_test)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSNU2qRXruRQ",
        "outputId": "fe7b774d-a7e3-4b22-d8e9-ec9462192a92"
      },
      "source": [
        "print(bst_grid.best_score_)\n",
        "print(bst_grid.best_params_)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.40028490028490027\n",
            "{'booster': 'gbtree', 'colsample_bytree': 1.0, 'learning_rate': 0.5, 'max_depth': 7, 'min_child_weight': 2, 'min_split_loss': 1, 'n_estimators': 500, 'num_class': 4, 'objective': 'multi:softprob', 'subsample': 0.75}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "9_ZeAiWSa9ly",
        "outputId": "5fc6161b-fc48-4f69-b460-de5e36ed1763"
      },
      "source": [
        "importance = pd.DataFrame(bst_grid.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>0.051391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>0.056830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>0.064883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>0.064909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>0.067701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.070348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>0.071431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>0.074009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>0.074984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>0.076561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>0.077686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>0.080625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>0.082380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>0.086263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                importance\n",
              "Number of cultivation field                       0.000000\n",
              "Gender_replaced                                   0.000000\n",
              "Sleeping_time                                     0.051391\n",
              "Livestock_time                                    0.056830\n",
              "Crop_time                                         0.064883\n",
              "Grasping power(kg)                                0.064909\n",
              "walking min from your house to Wangige market?    0.067701\n",
              "Age                                               0.070348\n",
              "Steps                                             0.071431\n",
              "Activity_level_2                                  0.074009\n",
              "Agrobiodiversity                                  0.074984\n",
              "percentage_production                             0.076561\n",
              "Total_happness                                    0.077686\n",
              "MIL                                               0.080625\n",
              "Number of people sharing the same pot             0.082380\n",
              "Economics_time                                    0.086263"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZoB_EJPnVPD",
        "outputId": "ed2973f1-c137-4112-a4d5-666d22801c54"
      },
      "source": [
        "print(\"Accuracy score (train): \", bst_grid.score(X_train, y_train))\n",
        "print('Accuracy:',accuracy_score(y_test,y_pred_xgb))\n",
        "# print(\"Accuracy score (test): \", bst_grid.score(X_test, y_test))\n",
        "print(bst_grid.best_estimator_) # ベストのパラメーターを持つ分類器"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score (train):  0.9238095238095239\n",
            "Accuracy: 0.48148148148148145\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1.0, gamma=0,\n",
            "              learning_rate=0.5, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=2, min_split_loss=1, missing=None,\n",
            "              n_estimators=500, n_jobs=1, nthread=None, num_class=4,\n",
            "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
            "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
            "              subsample=0.75, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryibD66hTqKz"
      },
      "source": [
        "現時点までの考察：\n",
        "---\n",
        "グリッドサーチを行った結果、ツリー系の分析、回帰系の分析を行った。\n",
        "\n",
        "正確性：\n",
        "XGboost = 0.40\n",
        "\n",
        "ランダムフォレスト　＝　0.44\n",
        "\n",
        "重回帰分析　＝　0.40\n",
        "\n",
        "LightGBM　＝　0.39\n",
        "\n",
        "ニューラルネットワーク　＝　0.44\n",
        "\n",
        "の結果だった。\n",
        "\n",
        "数値が上がらない理由\n",
        "そもそも分類データが少ない。データにバラツキがある。\n",
        "\n",
        "論文を読み直した結果、モデルの値はMAEとRMSEによって評価していたため、こちらでもその評価を行う。\n",
        "\n",
        "参考URL: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYvpI8g0UOUz"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmd8OCrZZhcP",
        "outputId": "d387b09e-0f83-4ce7-da3a-251b7de35a2d"
      },
      "source": [
        "#XGBoost\n",
        "mae_XGB = mean_absolute_error(y_test, y_pred_xgb)\n",
        "rmse_XGB = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "print(mae_XGB)\n",
        "print(rmse_XGB)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7777777777777778\n",
            "1.1385500851066221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqz-xws3aCr7",
        "outputId": "920af167-310d-468d-b7a4-3830bb25bc49"
      },
      "source": [
        "#LightGBM\n",
        "mae_GBM = mean_absolute_error(y_test, y_pred_GBM)\n",
        "rmse_GBM = np.sqrt(mean_squared_error(y_test, y_pred_GBM))\n",
        "print(mae_GBM)\n",
        "print(rmse_GBM)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9629629629629629\n",
            "1.247219128924647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lu5gfZra10L",
        "outputId": "12deaa41-9ff8-4450-bd56-5d89dda043e5"
      },
      "source": [
        "#SVM\n",
        "mae_SVM = mean_absolute_error(y_test, pre)\n",
        "rmse_SVM = np.sqrt(mean_squared_error(y_test, pre))\n",
        "print(mae_SVM)\n",
        "print(rmse_SVM)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.037037037037037\n",
            "1.3052600138300812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0YcILBNbO2P",
        "outputId": "cbf54b9f-4b06-4691-9c00-402d9d66072b"
      },
      "source": [
        "#ニューラルネットワーク\n",
        "mae_NN = mean_absolute_error(y_test, pre_NN)\n",
        "rmse_NN = np.sqrt(mean_squared_error(y_test, pre_NN))\n",
        "print(mae_NN)\n",
        "print(rmse_NN)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8518518518518519\n",
            "1.2018504251546631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5MBOt1dbhCV",
        "outputId": "62e79b7b-e4c2-4ce7-bd4f-112f1b241580"
      },
      "source": [
        "#重回帰分析\n",
        "mae_MLR = mean_absolute_error(y_test, pre_lr)\n",
        "rmse_MLR = np.sqrt(mean_squared_error(y_test, pre_lr))\n",
        "print(mae_MLR)\n",
        "print(rmse_MLR)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8888888888888888\n",
            "1.2171612389003692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJj6jk7b2e_",
        "outputId": "69f17c68-7686-4277-ceaa-a81d01da65c2"
      },
      "source": [
        "#ランダムフォレスト\n",
        "mae_RR = mean_absolute_error(y_test, y_pred_RR)\n",
        "rmse_RR = np.sqrt(mean_squared_error(y_test, y_pred_RR))\n",
        "print(mae_RR)\n",
        "print(rmse_RR)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8148148148148148\n",
            "1.1547005383792515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm3O6Kcbdu_D"
      },
      "source": [
        "MAEおよびRMSEの分析の結果：\n",
        "--\n",
        "XGboostが最も低いを値を示したが、0.77は依然として高い値である。\n",
        "\n",
        "今後の方針としては、サンプル数を増やすか、分析する特徴量を減らす必要があるかもしれい。\n",
        "現在は、説明変数はBMIをカテゴリー変数として扱っている。実数での変化を見るということできる。\n",
        "また、血圧のイベントについても調査することができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkBFyktutKn"
      },
      "source": [
        "オーバーサンプリング：\n",
        "---\n",
        "SMOTE\n",
        "\n",
        "参考URL:\n",
        "https://toukei-lab.com/imbalance-data-smote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20oxirP8cZsB",
        "outputId": "b0423bb9-1cc5-4b71-b7c5-af339514e514"
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyHQwFnBu0rg",
        "outputId": "8312ac24-b125-41e6-fbe4-6984aea05b83"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "x_resampled, y_resampled = sm.fit_sample(X_train, y_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjB5qbm5vD-H",
        "outputId": "9ee2e855-5443-4879-c1fe-dc0291b122d3"
      },
      "source": [
        "print(y_resampled.shape)\n",
        "print('=======================')\n",
        "print(np.array(y_train.shape))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156,)\n",
            "=======================\n",
            "[105]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHN_DzKqwQ5I"
      },
      "source": [
        "SMOTE後のLightGBM：\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_lKr0xBvN8Z",
        "outputId": "82a672be-56eb-4441-815c-60b0a897fe9f"
      },
      "source": [
        "# 試行するパラメータを羅列\n",
        "params = {\n",
        "    'num_leaves': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'reg_alpha': [0, 1, 2, 3, 4, 5,10, 100],\n",
        "    'reg_lambda': [10, 15, 18, 20, 21, 22, 23, 25, 27, 29]\n",
        "}\n",
        "\n",
        "grid_search_SMOTE = GridSearchCV(gbm, param_grid=params, cv=3)\n",
        "grid_search_SMOTE.fit(x_resampled, y_resampled)\n",
        "\n",
        "print(grid_search_SMOTE.best_score_)\n",
        "print(grid_search_SMOTE.best_params_)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5769230769230769\n",
            "{'num_leaves': 5, 'reg_alpha': 0, 'reg_lambda': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrMZNvccwixl"
      },
      "source": [
        "#予測XGBOOST\n",
        "y_pred_GBM_SMOTE = grid_search_SMOTE.predict(X_test)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "GCyjnGGaw0Un",
        "outputId": "4a0bdf8d-88f7-43dd-8ed0-df9d792303fe"
      },
      "source": [
        "importance = pd.DataFrame(grid_search_SMOTE.best_estimator_.feature_importances_, index=x_feature.columns, columns=['importance'])\n",
        "display(importance.sort_values('importance'))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of cultivation field</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of people sharing the same pot</th>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_replaced</th>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Livestock_time</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Steps</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walking min from your house to Wangige market?</th>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economics_time</th>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crop_time</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sleeping_time</th>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_happness</th>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Activity_level_2</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIL</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Agrobiodiversity</th>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grasping power(kg)</th>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentage_production</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                importance\n",
              "Number of cultivation field                             13\n",
              "Number of people sharing the same pot                   43\n",
              "Gender_replaced                                         53\n",
              "Livestock_time                                          60\n",
              "Steps                                                   74\n",
              "walking min from your house to Wangige market?          88\n",
              "Economics_time                                          96\n",
              "Crop_time                                              104\n",
              "Sleeping_time                                          106\n",
              "Total_happness                                         107\n",
              "Activity_level_2                                       112\n",
              "MIL                                                    128\n",
              "Agrobiodiversity                                       129\n",
              "Grasping power(kg)                                     129\n",
              "percentage_production                                  156\n",
              "Age                                                    176"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpx95F5rxCdH",
        "outputId": "5a612e57-3b57-4490-b10a-5bc05164cefe"
      },
      "source": [
        "#XGBoost_SMOTE\n",
        "mae_XGB_SMOTE = mean_absolute_error(y_test, y_pred_GBM_SMOTE)\n",
        "rmse_XGB_SMOTE = np.sqrt(mean_squared_error(y_test, y_pred_GBM_SMOTE))\n",
        "print(mae_XGB_SMOTE)\n",
        "print(rmse_XGB_SMOTE)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9629629629629629\n",
            "1.247219128924647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAAp4KYxzdsg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3J8lkSszcED"
      },
      "source": [
        "SMOTEしたランダムフォレスト：\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUZX1D1zza5t",
        "outputId": "078794c6-1759-4ed1-d7f6-07451de34ba4"
      },
      "source": [
        "from sklearn import tree\n",
        "# グリッドサーチ用のパラメータを辞書型で設定\n",
        "param = {'max_depth':[1, 2, 3, 4, 5],\n",
        "         'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "         'min_samples_split':[2, 3, 4, 5]}\n",
        " \n",
        "# 決定木による学習\n",
        "tree_SMOTE = GridSearchCV(tree.DecisionTreeClassifier(),   # グリッドサーチで決定木を定義\n",
        "                   param, cv=5, iid=True)\n",
        "tree_SMOTE.fit(x_resampled, y_resampled)                           # フィッティング\n",
        " \n",
        "# スコアとパラメータの組み合わせ\n",
        "scores = tree_SMOTE.cv_results_['mean_test_score']\n",
        "params = tree_SMOTE.cv_results_['params']\n",
        " \n",
        "# 結果の確認\n",
        "best_tree = tree_SMOTE.best_estimator_\n",
        "print('最良条件:\\n', best_tree)\n",
        "print('訓練スコア:\\n', best_tree.score(X_train, y_train))\n",
        "print('テストスコア:\\n', best_tree.score(X_test, y_test))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最良条件:\n",
            " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=2, min_samples_split=4,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "訓練スコア:\n",
            " 0.6952380952380952\n",
            "テストスコア:\n",
            " 0.4074074074074074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUDFy6dwxdzc"
      },
      "source": [
        "y_pred_RR_SMOTE = best_tree.predict(X_test)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEoBMGr10UCE",
        "outputId": "22c5f430-0401-466c-cdb6-edea60a967c0"
      },
      "source": [
        "#RR_SMOTE\n",
        "mae_RR_SMOTE = mean_absolute_error(y_test, y_pred_RR_SMOTE)\n",
        "rmse_RR_SMOTE = np.sqrt(mean_squared_error(y_test, y_pred_RR_SMOTE))\n",
        "print(mae_RR_SMOTE)\n",
        "print(rmse_RR_SMOTE)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8148148148148148\n",
            "1.1547005383792515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULCJFPDM0em_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}