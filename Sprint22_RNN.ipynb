{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint22_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhz5irf4CIzn/9SqYP9oyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harakenken22/diveintocode-ml/blob/master/Sprint22_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdTUsigmfjf4"
      },
      "source": [
        "Sprintの目的\n",
        "---\n",
        "スクラッチを通してリカレントニューラルネットワークの基礎を理解する\n",
        "\n",
        "- どのように学ぶか\n",
        "\n",
        "スクラッチでリカレントニューラルネットワークの実装を行います。\n",
        "\n",
        "- リカレントニューラルネットワークスクラッチ\n",
        "\n",
        "リカレントニューラルネットワーク（RNN） のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
        "\n",
        "フォワードプロパゲーションの実装を必須課題とし、バックプロパゲーションの実装はアドバンス課題とします。\n",
        "\n",
        "クラスの名前はScratchSimpleRNNClassifierとしてください。クラスの構造などは以前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。\n",
        "\n",
        "[DIVER](https://diver.diveintocode.jp/curriculums/1982)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqK0Ikjuf2rD"
      },
      "source": [
        "【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
        "---\n",
        "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
        "\n",
        "フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n",
        "\n",
        "バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64y13LJYf00T"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hedD4mZqfRk_"
      },
      "source": [
        "class Tanh():\n",
        "  \"\"\"\n",
        "  活性化関数定義：ハイパボリックタンジェント\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    self.Z = np.tanh(self.A)\n",
        "    return self.Z\n",
        "\n",
        "  def backward(self, dZ):\n",
        "    return dZ*(1-self.Z**2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjC0xWRch9AX"
      },
      "source": [
        "class SimpleInitializer:\n",
        "  def Wx(self, n_nodes1, n_nodes2):\n",
        "    \"\"\"\n",
        "    重みの初期化\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    W : 重み\n",
        "    \"\"\"\n",
        "    Wx = np.array([[1,3,5,7], [3,5,7,8]])/100\n",
        "    return Wx\n",
        "\n",
        "  def Wh(self, n_nodes1, n_nodes2):\n",
        "         \n",
        "    Wh = np.array([[1,3,5,7],\n",
        "                   [2,4,6,8],\n",
        "                   [3,5,7,8],\n",
        "                   [4,6,8,10]])/100\n",
        "    return Wh\n",
        "    \n",
        "  def B(self, n_nodaes2):\n",
        "    \"\"\"\n",
        "    バイアスの初期化\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    B : バイアス\n",
        "    \"\"\"\n",
        "    #np.zeros(n_nodes2)\n",
        "    B = np.array([1,1,1,1])\n",
        "    return B"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3un9jOm2uLx"
      },
      "source": [
        "$\n",
        "a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + B\\\\\n",
        "h_t = tanh(a_t)\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp3IfZFR13Jn"
      },
      "source": [
        "class FC:\n",
        "  def __init__(self, n_batch, input_nodes, output_nodes, initializer, activation):\n",
        "      self.n_batch = n_batch\n",
        "      self.input_nodes = input_nodes\n",
        "      self.output_nodes = output_nodes\n",
        "      self.initializer = initializer\n",
        "      self.activation = activation\n",
        "        \n",
        "        # 初期化\n",
        "        # initializerのメソッドで、self.Wx,self.Wh,self.Bを初期化する\n",
        "        \n",
        "      self.Wx = self.initializer.Wx(self.input_nodes, self.output_nodes)\n",
        "      self.Wh = self.initializer.Wh(self.output_nodes, self.output_nodes)\n",
        "      self.B = self.initializer.B(self.output_nodes)\n",
        "        \n",
        "      self.H = np.zeros([self.n_batch, self.output_nodes])\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, X):\n",
        "\n",
        "        #上記の式Aを作成\n",
        "      self.X = X\n",
        "      print('X:{}'.format(self.X))\n",
        "      self.A = np.dot(self.X, self.Wx) + np.dot(self.H, self.Wh) + self.B\n",
        "      print('A:{}'.format(self.A))\n",
        "      print('Wx:{}'.format(self.Wx))\n",
        "      print('Wh:{}'.format(self.Wh))\n",
        "     \n",
        "\n",
        "      self.H = self.activation.forward(self.A)\n",
        "      print('H:{}'.format(self.H))\n",
        "\n",
        "      return self.H"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PKZcmx05sGN"
      },
      "source": [
        "class ScratchSimpleRNNClassifier:\n",
        "  def __init__(self, n_nodes):\n",
        "    \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        \"\"\"\n",
        "    self.n_nodes = n_nodes\n",
        "  \n",
        "  def fit(self, X):\n",
        "      self.n_batch = X.shape[0]\n",
        "      self.n_features = X.shape[2]\n",
        "      initializer = SimpleInitializer()\n",
        "      #インスタンス化して別のクラスにわたす(initializer, Tanh())\n",
        "      affine = FC(self.n_batch, self.n_features, self.n_nodes, initializer, Tanh())\n",
        "      \n",
        "      for t in range(X.shape[1]):\n",
        "        h = affine.forward(X[:, t, :])\n",
        "        print('h.shape{}'.format(h.shape))\n",
        "\n",
        "      return h \n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_558Sj7P8B8X"
      },
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGevIewz8zzN",
        "outputId": "10d7b800-6148-420a-9be4-d9f0d4cc6773"
      },
      "source": [
        "print (x.shape)\n",
        "print (w_x.shape)\n",
        "print (w_h.shape)\n",
        "print (b.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 2)\n",
            "(2, 4)\n",
            "(4, 4)\n",
            "(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddhshwRp8_C-"
      },
      "source": [
        "# RNN = ScratchSimpleRNNClassifier(n_nodes)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyunsSSTLSR8"
      },
      "source": [
        "# RNN.fit(x)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Lqk0gZrkEY"
      },
      "source": [
        "#####下記は、関数の理解のために実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvSFK_WALY4B",
        "outputId": "3b82bc9a-5fa9-4f54-f845-6c91b94cba87"
      },
      "source": [
        "n_batch = x.shape[0]\n",
        "print(n_batch)\n",
        "n_features = x.shape[2]\n",
        "print(n_features)\n",
        "\n",
        "initializer = SimpleInitializer()\n",
        "#インスタンス化して別のクラスにわたす(initializer, Tanh())\n",
        "\n",
        "affine = FC(n_batch, n_features, n_nodes, initializer, Tanh())\n",
        "print(affine.forward)\n",
        "\n",
        "for t in range(x.shape[1]):\n",
        "  h = affine.forward(x[:, t, :])\n",
        "print(h)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "<bound method FC.forward of <__main__.FC object at 0x7f8efb0eb8d0>>\n",
            "X:[[0.01 0.02]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.76188798 0.76213958 0.76239095 0.76255841]]\n",
            "X:[[0.02 0.03]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.792209   0.8141834  0.83404912 0.84977719]]\n",
            "X:[[0.03 0.04]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.79494228 0.81839002 0.83939649 0.85584174]]\n",
            "[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4kUCUYVrhBJ"
      },
      "source": [
        "### 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
        "小さな配列でフォワードプロパゲーションを考えてみます。\n",
        "\n",
        "入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n",
        "\n",
        "ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ajLWPxdn6Y",
        "outputId": "2fbb7efe-26a2-4b59-dadc-7b8a57ebacd4"
      },
      "source": [
        "RNN = ScratchSimpleRNNClassifier(n_nodes)\n",
        "RNN.fit(x)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:[[0.01 0.02]]\n",
            "A:[[1.0007 1.0013 1.0019 1.0023]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.76188798 0.76213958 0.76239095 0.76255841]]\n",
            "h.shape(1, 4)\n",
            "X:[[0.02 0.03]]\n",
            "A:[[1.07733574 1.13931527 1.20129481 1.25535044]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.792209   0.8141834  0.83404912 0.84977719]]\n",
            "h.shape(1, 4)\n",
            "X:[[0.03 0.04]]\n",
            "A:[[1.08471832 1.15192269 1.21912707 1.27759095]]\n",
            "Wx:[[0.01 0.03 0.05 0.07]\n",
            " [0.03 0.05 0.07 0.08]]\n",
            "Wh:[[0.01 0.03 0.05 0.07]\n",
            " [0.02 0.04 0.06 0.08]\n",
            " [0.03 0.05 0.07 0.08]\n",
            " [0.04 0.06 0.08 0.1 ]]\n",
            "H:[[0.79494228 0.81839002 0.83939649 0.85584174]]\n",
            "h.shape(1, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQUz6Kj9rwTh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}